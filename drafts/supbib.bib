
@article{alberyPredictingGlobalMammalian2020,
  title = {Predicting the Global Mammalian Viral Sharing Network Using Phylogeography},
  author = {Albery, Gregory F. and Eskew, Evan A. and Ross, Noam and Olival, Kevin J.},
  year = {2020},
  month = may,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {2260},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-16153-4},
  abstract = {Understanding interspecific viral transmission is key to understanding viral ecology and evolution, disease spillover into humans, and the consequences of global change. Prior studies have uncovered macroecological drivers of viral sharing, but analyses have never attempted to predict viral sharing in a pan-mammalian context. Using a conservative modelling framework, we confirm that host phylogenetic similarity and geographic range overlap are strong, nonlinear predictors of viral sharing among species across the entire mammal class. Using these traits, we predict global viral sharing patterns of 4196 mammal species and show that our simulated network successfully predicts viral sharing and reservoir host status using internal validation and an external dataset. We predict high rates of mammalian viral sharing in the tropics, particularly among rodents and bats, and within- and between-order sharing differed geographically and taxonomically. Our results emphasize the importance of ecological and phylogenetic factors in shaping mammalian viral communities, and provide a robust, general model to predict viral host range and guide pathogen surveillance and conservation efforts.},
  copyright = {2020 The Author(s)},
  language = {en},
  file = {/home/devan/Zotero/storage/4G7245IA/Albery et al. - 2020 - Predicting the global mammalian viral sharing netw.pdf;/home/devan/Zotero/storage/87GIDA3A/s41467-020-16153-4.html}
}

@article{andersCountbasedDifferentialExpression2013,
  ids = {andersCountbasedDifferentialExpression2013a},
  title = {Count-Based Differential Expression Analysis of {{RNA}} Sequencing Data Using {{R}} and {{Bioconductor}}},
  author = {Anders, Simon and McCarthy, Davis J and Chen, Yunshun and Okoniewski, Michal and Smyth, Gordon K and Huber, Wolfgang and Robinson, Mark D},
  year = {2013},
  month = sep,
  journal = {Nature Protocols},
  volume = {8},
  number = {9},
  pages = {1765--1786},
  issn = {1754-2189, 1750-2799},
  doi = {10.1038/nprot.2013.099},
  language = {en},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/FGQS9QZG/Anders et al. - 2013 - Count-based differential expression analysis of RN.pdf;/home/devan/Zotero/storage/GEPSZ2KW/Anders et al. - 2013 - Count-based differential expression analysis of RN.pdf}
}

@article{baeleImprovingAccuracyDemographic2012,
  title = {Improving the {{Accuracy}} of {{Demographic}} and {{Molecular Clock Model Comparison While Accommodating Phylogenetic Uncertainty}}},
  author = {Baele, Guy and Lemey, Philippe and Bedford, Trevor and Rambaut, Andrew and Suchard, Marc A. and Alekseyenko, Alexander V.},
  year = {2012},
  month = sep,
  journal = {Molecular Biology and Evolution},
  volume = {29},
  number = {9},
  pages = {2157--2167},
  issn = {0737-4038},
  doi = {10.1093/molbev/mss084},
  abstract = {Recent developments in marginal likelihood estimation for model selection in the field of Bayesian phylogenetics and molecular evolution have emphasized the poor performance of the harmonic mean estimator (HME). Although these studies have shown the merits of new approaches applied to standard normally distributed examples and small real-world data sets, not much is currently known concerning the performance and computational issues of these methods when fitting complex evolutionary and population genetic models to empirical real-world data sets. Further, these approaches have not yet seen widespread application in the field due to the lack of implementations of these computationally demanding techniques in commonly used phylogenetic packages. We here investigate the performance of some of these new marginal likelihood estimators, specifically, path sampling (PS) and stepping-stone (SS) sampling for comparing models of demographic change and relaxed molecular clocks, using synthetic data and real-world examples for which unexpected inferences were made using the HME. Given the drastically increased computational demands of PS and SS sampling, we also investigate a posterior simulation-based analogue of Akaike's information criterion (AIC) through Markov chain Monte Carlo (MCMC), a model comparison approach that shares with the HME the appealing feature of having a low computational overhead over the original MCMC analysis. We confirm that the HME systematically overestimates the marginal likelihood and fails to yield reliable model classification and show that the AICM performs better and may be a useful initial evaluation of model choice but that it is also, to a lesser degree, unreliable. We show that PS and SS sampling substantially outperform these estimators and adjust the conclusions made concerning previous analyses for the three real-world data sets that we reanalyzed. The methods used in this article are now available in BEAST, a powerful user-friendly software package to perform Bayesian evolutionary analyses.},
  file = {/home/devan/Zotero/storage/8Y3IW2E5/Baele et al. - 2012 - Improving the Accuracy of Demographic and Molecula.pdf;/home/devan/Zotero/storage/6FFJJ8RP/1075653.html}
}

@article{beerenwinkelUltradeepSequencingAnalysis2011,
  title = {Ultra-Deep Sequencing for the Analysis of Viral Populations},
  author = {Beerenwinkel, Niko and Zagordi, Osvaldo},
  year = {2011},
  month = nov,
  journal = {Current Opinion in Virology},
  volume = {1},
  number = {5},
  pages = {413--418},
  issn = {1879-6257},
  doi = {10.1016/j.coviro.2011.07.008},
  abstract = {Next-generation sequencing allows for cost-effective probing of virus populations at an unprecedented level of detail. The massively parallel sequencing approach can detect low-frequency mutations and it provides a snapshot of the entire virus population. However, analyzing ultra-deep sequencing data obtained from diverse virus populations is challenging because of PCR and sequencing errors and short read lengths, such that the experiment provides only indirect evidence of the underlying viral population structure. Recent computational and statistical advances allow for accommodating some of the confounding factors, including methods for read error correction, haplotype reconstruction, and haplotype frequency estimation. With these methods ultra-deep sequencing can be more reliably used to analyze, in a quantitative manner, the genetic diversity of virus populations.},
  language = {en},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/V5PJMJ57/Beerenwinkel and Zagordi - 2011 - Ultra-deep sequencing for the analysis of viral po.pdf;/home/devan/Zotero/storage/GBZ9242Q/S1879625711000629.html}
}

@article{briandGeneralizedRobinsonFouldsDistance2020,
  title = {A Generalized {{Robinson}}-{{Foulds}} Distance for Labeled Trees},
  author = {Briand, Samuel and Dessimoz, Christophe and {El-Mabrouk}, Nadia and Lafond, Manuel and Lobinska, Gabriela},
  year = {2020},
  month = nov,
  journal = {BMC Genomics},
  volume = {21},
  number = {S10},
  pages = {779},
  issn = {1471-2164},
  doi = {10.1186/s12864-020-07011-0},
  abstract = {The Robinson-Foulds (RF) distance is a well-established measure between phylogenetic trees. Despite a lack of biological justification, it has the advantages of being a proper metric and being computable in linear time. For phylogenetic applications involving genes, however, a crucial aspect of the trees ignored by the RF metric is the type of the branching event (e.g. speciation, duplication, transfer, etc).Here, we extend RF to trees with labeled internal nodes by including a node flip operation, alongside edge contractions and extensions. We explore properties of this extended RF distance in the case of a binary labeling. In particular, we show that contrary to the unlabeled case, an optimal edit path may require contracting ``good'' edges, i.e. edges shared between the two trees. We provide a 2-approximation algorithm which is shown to perform well empirically. Looking ahead, computing distances between labeled trees opens up a variety of new algorithmic directions. Implementation and simulations available at https://github.com/DessimozLab/pylabeledrf.},
  language = {en},
  file = {/home/devan/Zotero/storage/VJRDQT6R/Briand et al. - 2020 - A generalized Robinson-Foulds distance for labeled.pdf}
}

@article{brockmanQualityScoresSNP2008,
  title = {Quality Scores and {{SNP}} Detection in Sequencing-by-Synthesis Systems},
  author = {Brockman, William and Alvarez, Pablo and Young, Sarah and Garber, Manuel and Giannoukos, Georgia and Lee, William L. and Russ, Carsten and Lander, Eric S. and Nusbaum, Chad and Jaffe, David B.},
  year = {2008},
  month = may,
  journal = {Genome Research},
  volume = {18},
  number = {5},
  pages = {763--770},
  issn = {1088-9051},
  doi = {10.1101/gr.070227.107},
  abstract = {Promising new sequencing technologies, based on sequencing-by-synthesis (SBS), are starting to deliver large amounts of DNA sequence at very low cost. Polymorphism detection is a key application. We describe general methods for improved quality scores and accurate automated polymorphism detection, and apply them to data from the Roche (454) Genome Sequencer 20. We assess our methods using known-truth data sets, which is critical to the validity of the assessments. We developed informative, base-by-base error predictors for this sequencer and used a variant of the phred binning algorithm to combine them into a single empirically derived quality score. These quality scores are more useful than those produced by the system software: They both better predict actual error rates and identify many more high-quality bases. We developed a SNP detection method, with variants for low coverage, high coverage, and PCR amplicon applications, and evaluated it on known-truth data sets. We demonstrate good specificity in single reads, and excellent specificity (no false positives in 215 kb of genome) in high-coverage data.},
  pmcid = {PMC2336812},
  pmid = {18212088},
  file = {/home/devan/Zotero/storage/JNWYUYHA/Brockman et al. - 2008 - Quality scores and SNP detection in sequencing-by-.pdf}
}

@article{clementGNUMAPAlgorithmUnbiased2010,
  title = {The {{GNUMAP}} Algorithm: Unbiased Probabilistic Mapping of Oligonucleotides from next-Generation Sequencing},
  shorttitle = {The {{GNUMAP}} Algorithm},
  author = {Clement, Nathan L. and Snell, Quinn and Clement, Mark J. and Hollenhorst, Peter C. and Purwar, Jahnvi and Graves, Barbara J. and Cairns, Bradley R. and Johnson, W. Evan},
  year = {2010},
  month = jan,
  journal = {Bioinformatics},
  volume = {26},
  number = {1},
  pages = {38--45},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btp614},
  abstract = {Motivation: The advent of next-generation sequencing technologies has increased the accuracy and quantity of sequence data, opening the door to greater opportunities in genomic research.Results: In this article, we present GNUMAP (Genomic Next-generation Universal MAPper), a program capable of overcoming two major obstacles in the mapping of reads from next-generation sequencing runs. First, we have created an algorithm that probabilistically maps reads to repeat regions in the genome on a quantitative basis. Second, we have developed a probabilistic Needleman\textendash Wunsch algorithm which utilizes \_prb.txt and \_int.txt files produced in the Solexa/Illumina pipeline to improve the mapping accuracy for lower quality reads and increase the amount of usable data produced in a given experiment.Availability: The source code for the software can be downloaded from http://dna.cs.byu.edu/gnumap.Contact:nathanlclement@gmail.comSupplementary information:Supplementary data are available at Bioinformatics online.},
  keywords = {important,revisit},
  file = {/home/devan/Zotero/storage/SG8RXG4Y/Clement et al_2010_The GNUMAP algorithm.pdf;/home/devan/Zotero/storage/MFV5P6E5/182331.html}
}

@article{cooperNeedlesStacksNeedles2011,
  title = {Needles in Stacks of Needles: Finding Disease-Causal Variants in a Wealth of Genomic Data},
  shorttitle = {Needles in Stacks of Needles},
  author = {Cooper, Gregory M. and Shendure, Jay},
  year = {2011},
  month = sep,
  journal = {Nature Reviews Genetics},
  volume = {12},
  number = {9},
  pages = {628--640},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg3046},
  abstract = {Genome and exome sequencing yield extensive catalogues of genetic variation in many individuals, but purely genetic approaches are often insufficiently powered to specifically identify the few variants that are causally related to any given phenotype. Indeed, variant interpretation is an increasingly important challenge at the interface of genetics, statistics and biology.Non-uniform estimates of the prior probability for variants to be biologically functional will be required to address this challenge. For disease studies, this can be translated into the need to estimate variant deleteriousness.Nearly all computational methods to predict deleteriousness use comparative sequence analysis, exploiting the fact that natural selection removes deleterious variants and tends to conserve the identities of important positions within genes and genomes.Assessment of protein-altering variants leverages both biochemical and evolutionary information, whereas non-coding variation is more challenging to study, given a lack of understanding of the molecular functionality of non-coding sequences relative to coding sequences.Experimental assessments of the functional impact of variants have historically relied on low-throughput assays. However, projects such as the Encyclopedia of DNA Elements (ENCODE) and the clever use of next-generation sequencing technologies are increasingly facilitating large-scale, systematic experimental assessment of genomic variation of many types.Ultimately, unified predictive methods that are applicable to both coding and non-coding variants that leverage both functional and evolutionary information will be crucial for the meaningful interpretation of personal genomes. However, important unknowns and unsolved phenomena, including the relative abundance and penetrance of coding versus non-coding variants, disagreements between evolutionary and experimental definitions of molecular functionality, and the vocabularies that define transcriptional regulatory elements, must first be addressed.},
  copyright = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  language = {en},
  file = {/home/devan/Zotero/storage/CMNZSMSG/Cooper and Shendure - 2011 - Needles in stacks of needles finding disease-caus.pdf;/home/devan/Zotero/storage/6Q2AJW57/nrg3046.html}
}

@article{depristoFrameworkVariationDiscovery2011,
  title = {A Framework for Variation Discovery and Genotyping Using Next-Generation {{DNA}} Sequencing Data},
  author = {DePristo, Mark A and Banks, Eric and Poplin, Ryan and Garimella, Kiran V and Maguire, Jared R and Hartl, Christopher and Philippakis, Anthony A and {del Angel}, Guillermo and Rivas, Manuel A and Hanna, Matt and McKenna, Aaron and Fennell, Tim J and Kernytsky, Andrew M and Sivachenko, Andrey Y and Cibulskis, Kristian and Gabriel, Stacey B and Altshuler, David and Daly, Mark J},
  year = {2011},
  month = may,
  journal = {Nature Genetics},
  volume = {43},
  number = {5},
  pages = {491--498},
  issn = {1061-4036, 1546-1718},
  doi = {10.1038/ng.806},
  language = {en},
  file = {/home/devan/Zotero/storage/BQNGSA7Q/DePristo et al. - 2011 - A framework for variation discovery and genotyping.pdf}
}

@article{doroninaPhylogeneticPositionEmended2005,
  title = {Phylogenetic Position and Emended Description of the Genus {{Methylovorus}}},
  author = {Doronina, N. V.},
  year = {2005},
  month = mar,
  journal = {INTERNATIONAL JOURNAL OF SYSTEMATIC AND EVOLUTIONARY MICROBIOLOGY},
  volume = {55},
  number = {2},
  pages = {903--906},
  issn = {1466-5026, 1466-5034},
  doi = {10.1099/ijs.0.63111-0},
  language = {en},
  file = {/home/devan/Zotero/storage/9GYZ4JPN/Doronina - 2005 - Phylogenetic position and emended description of t.pdf}
}

@article{eickRobustnessReconstructedAncestral2017,
  title = {Robustness of {{Reconstructed Ancestral Protein Functions}} to {{Statistical Uncertainty}}},
  author = {Eick, Geeta N. and Bridgham, Jamie T. and Anderson, Douglas P. and Harms, Michael J. and Thornton, Joseph W.},
  year = {2017},
  month = feb,
  journal = {Molecular Biology and Evolution},
  volume = {34},
  number = {2},
  pages = {247--261},
  issn = {0737-4038},
  doi = {10.1093/molbev/msw223},
  abstract = {Hypotheses about the functions of ancient proteins and the effects of historical mutations on them are often tested using ancestral protein reconstruction (APR)\textemdash phylogenetic inference of ancestral sequences followed by synthesis and experimental characterization. Usually, some sequence sites are ambiguously reconstructed, with two or more statistically plausible states. The extent to which the inferred functions and mutational effects are robust to uncertainty about the ancestral sequence has not been studied systematically. To address this issue, we reconstructed ancestral proteins in three domain families that have different functions, architectures, and degrees of uncertainty; we then experimentally characterized the functional robustness of these proteins when uncertainty was incorporated using several approaches, including sampling amino acid states from the posterior distribution at each site and incorporating the alternative amino acid state at every ambiguous site in the sequence into a single ``worst plausible case'' protein. In every case, qualitative conclusions about the ancestral proteins' functions and the effects of key historical mutations were robust to sequence uncertainty, with similar functions observed even when scores of alternate amino acids were incorporated. There was some variation in quantitative descriptors of function among plausible sequences, suggesting that experimentally characterizing robustness is particularly important when quantitative estimates of ancient biochemical parameters are desired. The worst plausible case method appears to provide an efficient strategy for characterizing the functional robustness of ancestral proteins to large amounts of sequence uncertainty. Sampling from the posterior distribution sometimes produced artifactually nonfunctional proteins for sequences reconstructed with substantial ambiguity.},
  file = {/home/devan/Zotero/storage/N2TCRJYF/Eick et al_2017_Robustness of Reconstructed Ancestral Protein Functions to Statistical.pdf;/home/devan/Zotero/storage/RLFMMKPB/2449965.html}
}

@article{ewingBaseCallingAutomatedSequencer1998,
  title = {Base-{{Calling}} of {{Automated Sequencer Traces Using}} {{{\emph{Phred}}}}{\emph{.}} {{II}}. {{Error Probabilities}}},
  author = {Ewing, Brent and Green, Phil},
  year = {1998},
  month = mar,
  journal = {Genome Research},
  volume = {8},
  number = {3},
  pages = {186--194},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.8.3.186},
  language = {en},
  keywords = {important,revisit},
  file = {/home/devan/Zotero/storage/LTRPJAB9/Ewing and Green - 1998 - Base-Calling of Automated Sequencer Traces Using .pdf}
}

@article{felsensteinInferringPhylogenies,
  title = {Inferring {{Phylogenies}}},
  author = {Felsenstein, Joseph},
  pages = {14},
  language = {en},
  file = {/home/devan/Zotero/storage/DPFJ27RK/Felsenstein - Inferring Phylogenies.pdf}
}

@article{fullerChallengesSequencingSynthesis2009,
  title = {The Challenges of Sequencing by Synthesis},
  author = {Fuller, Carl W. and Middendorf, Lyle R. and Benner, Steven A. and Church, George M. and Harris, Timothy and Huang, Xiaohua and Jovanovich, Stevan B. and Nelson, John R. and Schloss, Jeffery A. and Schwartz, David C. and Vezenov, Dmitri V.},
  year = {2009},
  month = nov,
  journal = {Nature Biotechnology},
  volume = {27},
  number = {11},
  pages = {1013--1023},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.1585},
  abstract = {DNA sequencing-by-synthesis (SBS) technology, using a polymerase or ligase enzyme as its core biochemistry, has already been incorporated in several second-generation DNA sequencing systems with significant performance. Notwithstanding the substantial success of these SBS platforms, challenges continue to limit the ability to reduce the cost of sequencing a human genome to \$100,000 or less. Achieving dramatically reduced cost with enhanced throughput and quality will require the seamless integration of scientific and technological effort across disciplines within biochemistry, chemistry, physics and engineering. The challenges include sample preparation, surface chemistry, fluorescent labels, optimizing the enzyme-substrate system, optics, instrumentation, understanding tradeoffs of throughput versus accuracy, and read-length/phasing limitations. By framing these challenges in a manner accessible to a broad community of scientists and engineers, we hope to solicit input from the broader research community on means of accelerating the advancement of genome sequencing technology.},
  copyright = {2009 Nature Publishing Group},
  language = {en},
  file = {/home/devan/Zotero/storage/LJYW3K7I/Fuller et al_2009_The challenges of sequencing by synthesis.pdf;/home/devan/Zotero/storage/3XXJPHPW/nbt.html}
}

@article{fumagalliQuantifyingPopulationGenetic2013a,
  title = {Quantifying {{Population Genetic Differentiation}} from {{Next}}-{{Generation Sequencing Data}}},
  author = {Fumagalli, Matteo and Vieira, Filipe G and Korneliussen, Thorfinn Sand and Linderoth, Tyler and {Huerta-S{\'a}nchez}, Emilia and Albrechtsen, Anders and Nielsen, Rasmus},
  year = {2013},
  month = nov,
  journal = {Genetics},
  volume = {195},
  number = {3},
  pages = {979--992},
  issn = {1943-2631},
  doi = {10.1534/genetics.113.154740},
  abstract = {Over the past few years, new high-throughput DNA sequencing technologies have dramatically increased speed and reduced sequencing costs. However, the use of these sequencing technologies is often challenged by errors and biases associated with the bioinformatical methods used for analyzing the data. In particular, the use of na\"ive methods to identify polymorphic sites and infer genotypes can inflate downstream analyses. Recently, explicit modeling of genotype probability distributions has been proposed as a method for taking genotype call uncertainty into account. Based on this idea, we propose a novel method for quantifying population genetic differentiation from next-generation sequencing data. In addition, we present a strategy for investigating population structure via principal components analysis. Through extensive simulations, we compare the new method herein proposed to approaches based on genotype calling and demonstrate a marked improvement in estimation accuracy for a wide range of conditions. We apply the method to a large-scale genomic data set of domesticated and wild silkworms sequenced at low coverage. We find that we can infer the fine-scale genetic structure of the sampled individuals, suggesting that employing this new method is useful for investigating the genetic relationships of populations sampled at low coverage.},
  file = {/home/devan/Zotero/storage/A2W4CCLH/Fumagalli et al. - 2013 - Quantifying Population Genetic Differentiation fro.pdf}
}

@article{garrisonHaplotypebasedVariantDetection2012,
  title = {Haplotype-Based Variant Detection from Short-Read Sequencing},
  author = {Garrison, Erik and Marth, Gabor},
  year = {2012},
  month = jul,
  journal = {arXiv:1207.3907 [q-bio]},
  eprint = {1207.3907},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  abstract = {The direct detection of haplotypes from short-read DNA sequencing data requires changes to existing small-variant detection methods. Here, we develop a Bayesian statistical framework which is capable of modeling multiallelic loci in sets of individuals with non-uniform copy number. We then describe our implementation of this framework in a haplotype-based variant detector, FreeBayes.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Genomics,Quantitative Biology - Quantitative Methods},
  file = {/home/devan/Zotero/storage/CFCUK4EL/Garrison and Marth - 2012 - Haplotype-based variant detection from short-read .pdf;/home/devan/Zotero/storage/V2NMEX5F/1207.html}
}

@article{gompertHierarchicalBayesianModel2011,
  title = {A {{Hierarchical Bayesian Model}} for {{Next}}-{{Generation Population Genomics}}},
  author = {Gompert, Zachariah and Buerkle, C. Alex},
  year = {2011},
  month = mar,
  journal = {Genetics},
  volume = {187},
  number = {3},
  pages = {903--917},
  publisher = {{Genetics}},
  issn = {0016-6731, 1943-2631},
  doi = {10.1534/genetics.110.124693},
  abstract = {The demography of populations and natural selection shape genetic variation across the genome and understanding the genomic consequences of these evolutionary processes is a fundamental aim of population genetics. We have developed a hierarchical Bayesian model to quantify genome-wide population structure and identify candidate genetic regions affected by selection. This model improves on existing methods by accounting for stochastic sampling of sequences inherent in next-generation sequencing (with pooled or indexed individual samples) and by incorporating genetic distances among haplotypes in measures of genetic differentiation. Using simulations we demonstrate that this model has a low false-positive rate for classifying neutral genetic regions as selected genes (i.e., {$\phi$}ST outliers), but can detect recent selective sweeps, particularly when genetic regions in multiple populations are affected by selection. Nonetheless, selection affecting just a single population was difficult to detect and resulted in a high false-negative rate under certain conditions. We applied the Bayesian model to two large sets of human population genetic data. We found evidence of widespread positive and balancing selection among worldwide human populations, including many genetic regions previously thought to be under selection. Additionally, we identified novel candidate genes for selection, several of which have been linked to human diseases. This model will facilitate the population genetic analysis of a wide range of organisms on the basis of next-generation sequence data.},
  chapter = {Investigations},
  copyright = {Copyright \textcopyright{} 2011 by the Genetics Society of America},
  language = {en},
  pmid = {21212231},
  file = {/home/devan/Zotero/storage/N9AU7Q6B/Gompert and Buerkle - 2011 - A Hierarchical Bayesian Model for Next-Generation .pdf;/home/devan/Zotero/storage/TDBVTA8I/903.html}
}

@article{harismendyEvaluationNextGeneration2009,
  title = {Evaluation of next Generation Sequencing Platforms for Population Targeted Sequencing Studies},
  author = {Harismendy, Olivier and Ng, Pauline C. and Strausberg, Robert L. and Wang, Xiaoyun and Stockwell, Timothy B. and Beeson, Karen Y. and Schork, Nicholas J. and Murray, Sarah S. and Topol, Eric J. and Levy, Samuel and Frazer, Kelly A.},
  year = {2009},
  month = mar,
  journal = {Genome Biology},
  volume = {10},
  number = {3},
  pages = {R32},
  issn = {1474-760X},
  doi = {10.1186/gb-2009-10-3-r32},
  abstract = {Next generation sequencing (NGS) platforms are currently being utilized for targeted sequencing of candidate genes or genomic intervals to perform sequence-based association studies. To evaluate these platforms for this application, we analyzed human sequence generated by the Roche 454, Illumina GA, and the ABI SOLiD technologies for the same 260 kb in four individuals.},
  keywords = {Additional Data File,Coverage Depth,False Negative Rate,Next Generation Sequencing,Next Generation Sequencing Technology},
  file = {/home/devan/Zotero/storage/3MSWQ694/Harismendy et al_2009_Evaluation of next generation sequencing platforms for population targeted.pdf;/home/devan/Zotero/storage/4DLGMRDB/gb-2009-10-3-r32.html}
}

@article{hawkinsNextgenerationGenomicsIntegrative2010,
  title = {Next-Generation Genomics: An Integrative Approach},
  shorttitle = {Next-Generation Genomics},
  author = {Hawkins, R. David and Hon, Gary C. and Ren, Bing},
  year = {2010},
  month = jul,
  journal = {Nature Reviews Genetics},
  volume = {11},
  number = {7},
  pages = {476--486},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg2795},
  abstract = {The integration of transcriptomic, genetic, genomic, epigenetic and network interaction data is crucial for a unified view of biological processes and to advance our understanding of human disease and biology.The genome sequence is a scaffold on which known annotations and experimental data can be assembled. It is useful to view these different levels of information together on a genome browser.Data integration can be used to identify functional elements in the genome, explore the function of genetic variation and improve understanding of gene regulation.Given large multidimensional data sets with minimal parameters, unsupervised learning techniques can be used to identify frequently occurring patterns in the data and therefore to suggest hypotheses.Carefully designed computational experiments for supervised integration can be used to test hypotheses on a global scale. Other supervised approaches, such as Bayesian networks, can also generate hypotheses of function.There are a range of online and stand-alone tools available to bench scientists for tackling large-scale data sets.Several analytical hurdles remain, which are being addressed by bioinformaticians.},
  copyright = {2010 Nature Publishing Group},
  language = {en},
  file = {/home/devan/Zotero/storage/XLXXM8C4/Hawkins et al. - 2010 - Next-generation genomics an integrative approach.pdf;/home/devan/Zotero/storage/FTNPGM75/nrg2795.html}
}

@article{hongProbabilisticAlignmentLeads2013,
  title = {Probabilistic Alignment Leads to Improved Accuracy and Read Coverage for Bisulfite Sequencing Data},
  author = {Hong, Changjin and Clement, Nathan L. and Clement, Spencer and Hammoud, Saher Sue and Carrell, Douglas T. and Cairns, Bradley R. and Snell, Quinn and Clement, Mark J. and Johnson, William Evan},
  year = {2013},
  month = nov,
  journal = {BMC Bioinformatics},
  volume = {14},
  number = {1},
  pages = {337},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-14-337},
  abstract = {DNA methylation has been linked to many important biological phenomena. Researchers have recently begun to sequence bisulfite treated DNA to determine its pattern of methylation. However, sequencing reads from bisulfite-converted DNA can vary significantly from the reference genome because of incomplete bisulfite conversion, genome variation, sequencing errors, and poor quality bases. Therefore, it is often difficult to align reads to the correct locations in the reference genome. Furthermore, bisulfite sequencing experiments have the additional complexity of having to estimate the DNA methylation levels within the sample.},
  keywords = {Bisulfite sequencing,DNA methylation,Parallel processing,Probabilistic alignment},
  file = {/home/devan/Zotero/storage/ZUEFY6JX/Hong et al_2013_Probabilistic alignment leads to improved accuracy and read coverage for.pdf;/home/devan/Zotero/storage/MD5UXWVX/1471-2105-14-337.html}
}

@article{jahnTreeInferenceSinglecell2016,
  title = {Tree Inference for Single-Cell Data},
  author = {Jahn, Katharina and Kuipers, Jack and Beerenwinkel, Niko},
  year = {2016},
  month = dec,
  journal = {Genome Biology},
  volume = {17},
  number = {1},
  pages = {86},
  issn = {1474-760X},
  doi = {10.1186/s13059-016-0936-x},
  abstract = {Understanding the mutational heterogeneity within tumors is a keystone for the development of efficient cancer therapies. Here, we present SCITE, a stochastic search algorithm to identify the evolutionary history of a tumor from noisy and incomplete mutation profiles of single cells. SCITE comprises a flexible Markov chain Monte Carlo sampling scheme that allows the user to compute the maximum-likelihood mutation history, to sample from the posterior probability distribution, and to estimate the error rates of the underlying sequencing experiments. Evaluation on real cancer data and on simulation studies shows the scalability of SCITE to present-day single-cell sequencing data and improved reconstruction accuracy compared to existing approaches.},
  language = {en},
  file = {/home/devan/Zotero/storage/XAR5CDVJ/Jahn et al. - 2016 - Tree inference for single-cell data.pdf}
}

@article{keithSimulatedAnnealingAlgorithm2002,
  title = {A Simulated Annealing Algorithm for Finding Consensus Sequences},
  author = {Keith, Jonathan M. and Adams, Peter and Bryant, Darryn and Kroese, Dirk P. and Mitchelson, Keith R. and Coachran, Duncan A. E. and Lala, Gita H.},
  year = {2002},
  month = nov,
  journal = {Bioinformatics},
  volume = {18},
  number = {11},
  pages = {1494--1499},
  publisher = {{Oxford University Press}},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/18.11.1494},
  language = {English},
  pmid = {12424121},
  file = {/home/devan/Zotero/storage/YMGXP96H/Keith et al. - 2002 - A simulated annealing algorithm for finding consen.pdf;/home/devan/Zotero/storage/VXPMQMVG/a-simulated-annealing-algorithm-for-finding-consensus-sequences.html}
}

@misc{kimEffectsFabricatedMethod2011,
  title = {Effects of {{Fabricated Method}} on the {{Coefficient}} of {{Friction}} of {{Al2O3}}-15 Wt\% {{ZrO2}}-3 Wt\% {{Solid Lubricant Composites}}},
  author = {Kim, Seung Ho and Cura, M. Erkin and S{\"o}derberg, Outi and Hannula, Simo Pekka and Lee, Soo Wohn},
  year = {2011},
  journal = {Materials Science Forum},
  volume = {695},
  pages = {231--234},
  publisher = {{Trans Tech Publications Ltd}},
  issn = {1662-9752},
  doi = {10.4028/www.scientific.net/MSF.695.231},
  abstract = {The coefficient of friction was very important factor for the applications of high temperature parts. In vehicles, the coefficient of friction was decreased due to lubricants as like engine oil etc. Lubricant such as oils is difficult to apply at high temperature. To apply high temperature parts, lubricants were demanded for high temperature stability. This work is to use the pulsed electric current sintering (PECS) technique and the atmospheric plasma spraying (APS) method in order to make self-lubricating Al2O3-15wt\% ZrO2-solid lubricant composites. We focused on the coefficient of friction for the fabrication method of self-lubricating Al2O3-15wt\% ZrO2-solid lubricant composites. We compared with the coefficient of friction of PECSed and APSed composites. The surface roughness of PECSed Al2O3-15wt\% ZrO2-solid lubricant composites were 0.06 \textasciitilde{} 0.31 {$\mu$}m of Ra and 10.16 \textasciitilde{} 33.12 {$\mu$}m of Ry. In the case of APSed Al2O3-15wt\% ZrO2-solid lubricant composites, as-coated samples were 6.56 \textasciitilde{} 11.42 {$\mu$}m of Ra and 59.68 \textasciitilde{} 81.79 {$\mu$}m of Ry, and polished samples were 1.12 \textasciitilde{} 3.70 {$\mu$}m of Ra and 11.66 \textasciitilde{} 32.22 {$\mu$}m of Ry. The coefficient of friction of PECSed and APSed Al2O3-15wt\% ZrO2-solid lubricant composites were 0.19 \textasciitilde{} 0.49 and 0.41 \textasciitilde{} 0.61, respectively.},
  howpublished = {https://www.scientific.net/MSF.695.231},
  isbn = {9783037852224},
  language = {en},
  file = {/home/devan/Zotero/storage/TTK4NWM5/MSF.695.html}
}

@article{kimEstimationAlleleFrequency2011,
  title = {Estimation of Allele Frequency and Association Mapping Using Next-Generation Sequencing Data},
  author = {Kim, Su Yeon and Lohmueller, Kirk E. and Albrechtsen, Anders and Li, Yingrui and Korneliussen, Thorfinn and Tian, Geng and Grarup, Niels and Jiang, Tao and Andersen, Gitte and Witte, Daniel and Jorgensen, Torben and Hansen, Torben and Pedersen, Oluf and Wang, Jun and Nielsen, Rasmus},
  year = {2011},
  month = jun,
  journal = {BMC Bioinformatics},
  volume = {12},
  number = {1},
  pages = {231},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-12-231},
  abstract = {Estimation of allele frequency is of fundamental importance in population genetic analyses and in association mapping. In most studies using next-generation sequencing, a cost effective approach is to use medium or low-coverage data (e.g., {$<$} 15X). However, SNP calling and allele frequency estimation in such studies is associated with substantial statistical uncertainty because of varying coverage and high error rates.},
  language = {en},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/G7VCE6TY/Kim et al. - 2011 - Estimation of allele frequency and association map.pdf}
}

@article{kozlovModelsOptimizationsTools2018,
  title = {Models, {{Optimizations}}, and {{Tools}} for {{Large}}-{{Scale Phylogenetic Inference}}, {{Handling Sequence Uncertainty}},  and {{Taxonomic Validation}}},
  author = {Kozlov, Oleksii},
  year = {2018},
  publisher = {{Karlsruhe}},
  doi = {10.5445/IR/1000081661},
  abstract = {Das Konzept der Evolution ist in der modernen Biologie von zentraler Bedeutung.  Deswegen liefert die Phylogenetik, die Lehre \"uber die Verwandschaften und Abstam-  mung von Organismen bzw. Spezies, entscheidende Hinweise zur Entschl\"usselung  einer Vielzahl biologischer Prozesse. Phylogenetische Stammb\"aume sind einerseits  f\"ur die Grundlagenforschung wichtig, da sie in Studien \"uber die Diversifizierung und  Umweltanpassung einzelner Organismengruppen (z.B. Insekten oder V\"ogel) bis hin  zu der gro\ss en Herausforderung, die Entstehung und Entwicklung aller Lebensfor-  men in einem umfassenden evolution\"aren Baum darzustellen (der sog. Tree of Life)  Anwendung finden. Andererseits werden phylogenetische Methoden auch in prax-  isnahen Anwendungen eingesetzt, um beispielsweise die Verbreitungsdynamik von  HIV-Infektionen oder, die Heterogenit\"at der Krebszellen eines Tumors, zu verstehen.  Den aktuellen Stand der Technik in der Stammbaumrekonstruktion stellen Meth-  oden Maximum Likelihood (ML) und Bayes'sche Inferenz (BI) dar, welche auf der  Analyse molekularer Sequenzendaten (DNA und Proteine) anhand probabilistis-  cher Evolutionsmodelle basieren. Diese Methoden weisen eine hohe Laufzeitkom-  plexit\"at auf (N P -schwer), welche die Entwicklung effizienter Heuristiken unabding-  bar macht. Hinzu kommt, dass die Berechnung der Zielfunktion (sog. Phylogenetic  Likelihood Function, PLF) neben einem hohen Speicherverbrauch auch eine Vielzahl  an Gleitkommaarithmetik-Operationen erfordert und somit extrem rechenaufwendig  ist.  Die neuesten Entwicklungen im Bereich der DNA-Sequenzierung (Next Gener-  ation Sequencing, NGS) steigern kontinuierlich den Durchsatz und senken zugleich  die Sequenzierungskosten um ein Vielfaches. F\"ur die Phylogenetik hat dies zur  Folge, dass die Dimensionen der zu analysierenden Datens\"atze alle 2\textendash 3 Jahre, um  eine Gr\"ossenordnung zunhemen. War es bisher \"ublich, einige Dutzend bis Hun-  derte Spezies anhand einzelner bzw. weniger Gene zu analysieren (Sequenzl\"ange:  1\textendash 10 Kilobasen), stellen derzeit Studien mit Tausenden Sequenzen oder Genen keine  Seltenheit mehr dar. In den n\"achsten 1\textendash 2 Jahren ist zu erwarten, dass die Anal-  ysen Tausender bis Zehntausender vollst\"andiger Genome bzw. Transkriptome (Se-  quenzl\"ange: 1\textendash 100 Megabasen und mehr) anstehen. Um diesen Aufgaben gewachsen  zu sein, m\"ussen die bestehenden Methoden weiterentwickelt und optimiert werden,  um vor allem H\"ochstleistungsrechner sowie neue Hardware-Architekturen optimal  nutzen zu k\"onnen.  Au\ss erdem f\"uhrt die sich beschleunigende Speicherung von Sequenzen in \"offentli-  chen Datenbanken wie NCBI GenBank (und ihren Derivaten) dazu, dass eine hohe  Qualit\"at der Sequenzannotierungen (z. B. Organismus- bzw. Speziesname, tax-  onomische Klassifikation, Name eines Gens usw.) nicht zwangsl\"aufig gew\"ahrleistet  ist. Das h\"angt unter anderem auch damit zusammen, dass eine zeitnahe Korrektur  durch entsprechende Experten nicht mehr m\"oglich ist, solange ihnen keine ad\"aquaten  Software-Tools zur Verf\"ugung stehen.  In dieser Doktroarbeit leisten wir mehrere Beitr\"age zur Bew\"altigung der oben  genannten Herausforderungen.  Erstens haben wir ExaML, eine dedizierte Software zur ML-basierten Stamm-  baumrekonstruktion f\"ur H\"ochstleistungsrechner, auf den Intel Xeon Phi Hardware-  beschleuniger portiert. Der Xeon Phi bietet im Vergleich zu klassischen x86 CPUs  eine h\"ohere Rechenleistung, die allerdings nur anhand architekturspezifischer Op-  timierungen vollst\"andig genutzt werden kann. Aus diesem Grund haben wir zum  einen die PLF-Berechnung f\"ur die 512-bit-Vektoreinheit des Xeon Phi umstrukturi-  ert und optimiert. Zum anderen haben wir die in ExaML bereits vorhandene reine  MPI-Parallelisierung durch eine hybride MPI/OpenMP-L\"osung ersetzt. Diese hy-  bride L\"osung weist eine wesentlich bessere Skalierbarkeit f\"ur eine hohe Zahl von  Kernen bzw. Threads innerhalb eines Rechenknotens auf (\&gt;100 HW-Threads f\"ur  Xeon Phi).  Des Weiteren haben wir eine neue Software zur ML-Baumrekonstruktion na-  mens RAxML-NG entwickelt. Diese implementiert, bis auf kleinere Anpassungen, zwar  denselben Suchalgorithmus wie das weit verbreitete Programm RAxML, bietet aber  gegen\"uber RAxML mehrere Vorteile: (a) dank den sorgf\"altigen Optimierungen der  PLF-Berechnung ist es gelungen, die Laufzeiten um den Faktor 2 bis 3 zu reduzieren  (b) die Skalierbarkeit auf extrem gro\ss en Eingabedatens\"atzen wurde verbessert, in-  dem ineffiziente topologische Operationen eliminiert bzw. optimiert wurden, (c) die  bisher nur in ExaML verf\"ugbaren, f\"ur gro\ss e Datens\"atze relevanten Funktionen wie  Checkpointing sowie ein dedizierter Datenverteilungsalgorithmus wurden nachimple-  mentiert (d) dem Benutzer steht eine gr\"o\ss ere Auswahl an statistischen DNA-Evo-  lutionsmodellen zur Verf\"ugung, die zudem flexibler kombiniert und parametrisiert  werden k\"onnen (e) die Weiterentwicklung der Software wird aufgrund der modularen  Architektur wesentlich erleichtert (die Funktionen zur PLF-Berechnung wurden in  eine gesonderte Bibliothek ausgeglidert).  Als n\"achstes haben wir untersucht, wie sich Sequenzierungsfehler auf die Genau-  igkeit phylogenetischr Stammbaumrekonstruktionen auswirken. Wir modifizieren  den RAxML bzw. RAxML-NG Code dahingehend, dass sowohl die explizite Angabe von  Fehlerwahrscheinlichkeiten als auch die automatische Sch\"atzung von Fehlerraten  mittels der ML-Methode m\"oglich ist. Unsere Simulationen zeigen: (a) Wenn die  Fehler gleichverteilt sind, kann die Fehlerrate direkt aus den Sequenzdaten gesch\"atzt  werden. (b) Ab einer Fehlerrate von ca. 1\% liefert die Baumrekonstruktion unter  Ber\"ucksichtigung des Fehlermodells genauere Ergebnisse als die klassische Methode,  welche die Eingabe als fehlerfrei annimmt.  Ein weiterer Beitrag im Rahmen dieser Arbeit ist die Software-Pipeline SATIVA  zur rechnergest\"utzten Identifizierung und Korrektur fehlerhafter taxonomischer An-  notierungen in gro\ss en Sequenzendatenbanken. Der Algorithmus funktioniert wie  folgt: f\"ur jede Sequenz wird die Platzierung im Stammbaum mit dem h\"ochst-  m\"oglichen Likelihood-Wert ermittelt und anschlie\ss end gepr\"uft, ob diese mit der  vorgegeben taxonomischen Klassifikation \"ubereinstimmt. Ist dies nicht der Fall,  wird also eine Sequenz beispielsweise innerhalb einer anderen Gattung platziert,  wird die Sequenz als falsch annotiert gemeldet, und es wird eine entsprechende  Umklassifizierung vorgeschlagen. Auf simulierten Datens\"atzen mit zuf\"allig eingef\"ug-  ten Fehlern, erreichte unsere Pipeline eine hohe Identifikationsquote (\&gt;90\%) sowie  Genauigkeit (\&gt;95\%). Zur Evaluierung anhand empirischer Daten, haben wir vier  \"offentliche rRNA Datenbanken untersucht, welche zur Klassifizierung von Bakterien  h\"aufig als Referenz benutzt werden. Dabei haben wir je nach Datenbank 0.2\% bis  2.5\% aller Sequenzen als potenzielle Fehlannotierungen identifiziert.},
  copyright = {Open Access, KITopen License},
  language = {en},
  file = {/home/devan/Zotero/storage/P6ANTRM5/dissAlexey.pdf}
}

@article{kuhnerCorrectingSequencingError2014,
  title = {Correcting for {{Sequencing Error}} in {{Maximum Likelihood Phylogeny Inference}}},
  author = {Kuhner, Mary K and McGill, James},
  year = {2014},
  month = dec,
  journal = {G3 Genes|Genomes|Genetics},
  volume = {4},
  number = {12},
  pages = {2545--2552},
  issn = {2160-1836},
  doi = {10.1534/g3.114.014365},
  abstract = {Accurate phylogenies are critical to taxonomy as well as studies of speciation processes and other evolutionary patterns. Accurate branch lengths in phylogenies are critical for dating and rate measurements. Such accuracy may be jeopardized by unacknowledged sequencing error. We use simulated data to test a correction for DNA sequencing error in maximum likelihood phylogeny inference. Over a wide range of data polymorphism and true error rate, we found that correcting for sequencing error improves recovery of the branch lengths, even if the assumed error rate is up to twice the true error rate. Low error rates have little effect on recovery of the topology. When error is high, correction improves topological inference; however, when error is extremely high, using an assumed error rate greater than the true error rate leads to poor recovery of both topology and branch lengths. The error correction approach tested here was proposed in 2004 but has not been widely used, perhaps because researchers do not want to commit to an estimate of the error rate. This study shows that correction with an approximate error rate is generally preferable to ignoring the issue.},
  language = {en},
  file = {/home/devan/Zotero/storage/S7W48MHB/Kuhner and McGill - 2014 - Correcting for Sequencing Error in Maximum Likelih.pdf}
}

@article{kuoEAGLEExplicitAlternative2018,
  title = {{{EAGLE}}: {{Explicit Alternative Genome Likelihood Evaluator}}},
  shorttitle = {{{EAGLE}}},
  author = {Kuo, Tony and Frith, Martin C. and Sese, Jun and Horton, Paul},
  year = {2018},
  month = apr,
  journal = {BMC Medical Genomics},
  volume = {11},
  number = {2},
  pages = {28},
  issn = {1755-8794},
  doi = {10.1186/s12920-018-0342-1},
  abstract = {Reliable detection of genome variations, especially insertions and deletions (indels), from single sample DNA sequencing data remains challenging, partially due to the inherent uncertainty involved in aligning sequencing reads to the reference genome. In practice a variety of ad hoc quality filtering methods are employed to produce more reliable lists of putative variants, but the resulting lists typically still include numerous false positives. Thus it would be desirable to be able to rigorously evaluate the degree to which each putative variant is supported by the data. Unfortunately, users who wish to do this, e.g. for the purpose of prioritizing validation experiments, have been faced with limited options.},
  keywords = {Generative probabilistic models,Genomic variants,Next generation sequencing data analysis,Variant calling,Variant quality score},
  file = {/home/devan/Zotero/storage/9PK7Z5BN/Kuo et al. - 2018 - EAGLE Explicit Alternative Genome Likelihood Eval.pdf;/home/devan/Zotero/storage/Z6N45RNG/s12920-018-0342-1.html}
}

@article{liAdjustQualityScores2004,
  title = {Adjust Quality Scores from Alignment and Improve Sequencing Accuracy},
  author = {Li, Ming and Nordborg, Magnus and Li, Lei M.},
  year = {2004},
  journal = {Nucleic Acids Research},
  volume = {32},
  number = {17},
  pages = {5183--5191},
  issn = {0305-1048},
  doi = {10.1093/nar/gkh850},
  abstract = {In shotgun sequencing, statistical reconstruction of a consensus from alignment requires a model of measurement error. Churchill and Waterman proposed one such model and an expectation\textendash maximization (EM) algorithm to estimate sequencing error rates for each assembly matrix. Ewing and Green defined Phred quality scores for base-calling from sequencing traces by training a model on a large amount of data. However, sample preparations and sequencing machines may work under different conditions in practice and therefore quality scores need to be adjusted. Moreover, the information given by quality scores is incomplete in the sense that they do not describe error patterns. We observe that each nucleotide base has its specific error pattern that varies across the range of quality values. We develop models of measurement error for shotgun sequencing by combining the two perspectives above. We propose a logistic model taking quality scores as covariates. The model is trained by a procedure combining an EM algorithm and model selection techniques. The training results in calibration of quality values and leads to a more accurate construction of consensus. Besides Phred scores obtained from ABI sequencers, we apply the same technique to calibrate quality values that come along with Beckman sequencers.},
  pmcid = {PMC521663},
  pmid = {15459287},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/IID9CE4G/Li et al. - 2004 - Adjust quality scores from alignment and improve s.pdf}
}

@article{liMappingShortDNA2008,
  title = {Mapping Short {{DNA}} Sequencing Reads and Calling Variants Using Mapping Quality Scores},
  author = {Li, Heng and Ruan, Jue and Durbin, Richard},
  year = {2008},
  month = jan,
  journal = {Genome Research},
  volume = {18},
  number = {11},
  pages = {1851--1858},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.078212.108},
  abstract = {New sequencing technologies promise a new era in the use of DNA sequence. However, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. In particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. Here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. We describe the software MAQ that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. MAQ makes full use of mate-pair information and estimates the error probability of each read alignment. Error probabilities are also derived for the final genotype calls, using a Bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. Both read mapping and genotype calling are evaluated on simulated data and real data. MAQ is accurate, efficient, versatile, and user-friendly. It is freely available at http://maq.sourceforge.net.},
  language = {en},
  pmid = {18714091},
  file = {/home/devan/Zotero/storage/8X96P33S/Li et al. - 2008 - Mapping short DNA sequencing reads and calling var.pdf;/home/devan/Zotero/storage/AQ4WZCI2/1851.html}
}

@article{liMappingShortDNA2008a,
  title = {Mapping Short {{DNA}} Sequencing Reads and Calling Variants Using Mapping Quality Scores},
  author = {Li, Heng and Ruan, Jue and Durbin, Richard},
  year = {2008},
  month = nov,
  journal = {Genome Research},
  volume = {18},
  number = {11},
  pages = {1851--1858},
  issn = {1088-9051},
  doi = {10.1101/gr.078212.108},
  abstract = {New sequencing technologies promise a new era in the use of DNA sequence. However, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. In particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. Here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. We describe the software MAQ that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. MAQ makes full use of mate-pair information and estimates the error probability of each read alignment. Error probabilities are also derived for the final genotype calls, using a Bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. Both read mapping and genotype calling are evaluated on simulated data and real data. MAQ is accurate, efficient, versatile, and user-friendly. It is freely available at http://maq.sourceforge.net.},
  language = {eng},
  pmcid = {PMC2577856},
  pmid = {18714091},
  keywords = {Algorithms,Bayes Theorem,Chromosome Mapping,Computer Simulation,Diploidy,DNA,DNA; Bacterial,Genome; Bacterial,Genome; Human,Humans,Polymorphism; Single Nucleotide,Reproducibility of Results,Salmonella paratyphi A,Sequence Alignment,Sequence Analysis; DNA,Software},
  file = {/home/devan/Zotero/storage/D6C9SL9J/Li et al_2008_Mapping short DNA sequencing reads and calling variants using mapping quality.pdf}
}

@article{liNovoAssemblyHuman2010,
  title = {De Novo Assembly of Human Genomes with Massively Parallel Short Read Sequencing},
  author = {Li, Ruiqiang and Zhu, Hongmei and Ruan, Jue and Qian, Wubin and Fang, Xiaodong and Shi, Zhongbin and Li, Yingrui and Li, Shengting and Shan, Gao and Kristiansen, Karsten and Li, Songgang and Yang, Huanming and Wang, Jian and Wang, Jun},
  year = {2010},
  month = feb,
  journal = {Genome Research},
  volume = {20},
  number = {2},
  pages = {265--272},
  issn = {1088-9051},
  doi = {10.1101/gr.097261.109},
  abstract = {Next-generation massively parallel DNA sequencing technologies provide ultrahigh throughput at a substantially lower unit data cost; however, the data are very short read length sequences, making de novo assembly extremely challenging. Here, we describe a novel method for de novo assembly of large genomes from short read sequences. We successfully assembled both the Asian and African human genome sequences, achieving an N50 contig size of 7.4 and 5.9 kilobases (kb) and scaffold of 446.3 and 61.9 kb, respectively. The development of this de novo short read assembly method creates new opportunities for building reference sequences and carrying out accurate analyses of unexplored genomes in a cost-effective way.},
  pmcid = {PMC2813482},
  pmid = {20019144},
  file = {/home/devan/Zotero/storage/GTVNYLFL/Li et al_2010_De novo assembly of human genomes with massively parallel short read sequencing.pdf}
}

@article{lippiPotentialPreanalyticalAnalytical2020,
  title = {Potential Preanalytical and Analytical Vulnerabilities in the Laboratory Diagnosis of Coronavirus Disease 2019 ({{COVID}}-19)},
  author = {Lippi, Giuseppe and Simundic, Ana-Maria and Plebani, Mario},
  year = {2020},
  month = jun,
  journal = {Clinical Chemistry and Laboratory Medicine},
  volume = {58},
  number = {7},
  pages = {1070--1076},
  issn = {1437-4331},
  doi = {10.1515/cclm-2020-0285},
  abstract = {A novel zoonotic coronavirus outbreak is spreading all over the world. This pandemic disease has now been defined as novel coronavirus disease 2019 (COVID-19), and is sustained by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). As the current gold standard for the etiological diagnosis of SARS-CoV-2 infection is (real time) reverse transcription polymerase chain reaction (rRT-PCR) on respiratory tract specimens, the diagnostic accuracy of this technique shall be considered a foremost prerequisite. Overall, potential RT-PCR vulnerabilities include general preanalytical issues such as identification problems, inadequate procedures for collection, handling, transport and storage of the swabs, collection of inappropriate or inadequate material (for quality or volume), presence of interfering substances, manual errors, as well as specific aspects such as sample contamination and testing patients receiving antiretroviral therapy. Some analytical problems may also contribute to jeopardize the diagnostic accuracy, including testing outside the diagnostic window, active viral recombination, use of inadequately validated assays, insufficient harmonization, instrument malfunctioning, along with other specific technical issues. Some practical indications can hence be identified for minimizing the risk of diagnostic errors, encompassing the improvement of diagnostic accuracy by combining clinical evidence with results of chest computed tomography (CT) and RT-PCR, interpretation of RT-PCR results according to epidemiologic, clinical and radiological factors, recollection and testing of upper (or lower) respiratory specimens in patients with negative RT-PCR test results and high suspicion or probability of infection, dissemination of clear instructions for specimen (especially swab) collection, management and storage, together with refinement of molecular target(s) and thorough compliance with analytical procedures, including quality assurance.},
  language = {eng},
  pmid = {32172228},
  keywords = {Betacoronavirus,Clinical Laboratory Techniques,coronavirus,Coronavirus,Coronavirus Infections,COVID-19,diagnosis,Disease Outbreaks,Humans,Medical Errors,Pandemics,Pneumonia; Viral,reverse transcription polymerase chain reaction (RT-PCR),SARS-CoV-2,Scientific Experimental Error,Specimen Handling},
  file = {/home/devan/Zotero/storage/7XZRKIS3/Lippi et al. - 2020 - Potential preanalytical and analytical vulnerabili.pdf}
}

@article{liSequenceAlignmentMap2009,
  title = {The {{Sequence Alignment}}/{{Map}} Format and {{SAMtools}}},
  author = {Li, Heng and Handsaker, Bob and Wysoker, Alec and Fennell, Tim and Ruan, Jue and Homer, Nils and Marth, Gabor and Abecasis, Goncalo and Durbin, Richard},
  year = {2009},
  month = aug,
  journal = {Bioinformatics},
  volume = {25},
  number = {16},
  pages = {2078--2079},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btp352},
  abstract = {Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms. It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released. SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments., Availability: http://samtools.sourceforge.net, Contact: rd@sanger.ac.uk},
  pmcid = {PMC2723002},
  pmid = {19505943},
  file = {/home/devan/Zotero/storage/GGDNMHFH/Li et al_2009_The Sequence Alignment-Map format and SAMtools.pdf}
}

@article{liSNPDetectionMassively2009,
  title = {{{SNP}} Detection for Massively Parallel Whole-Genome Resequencing},
  author = {Li, Ruiqiang and Li, Yingrui and Fang, Xiaodong and Yang, Huanming and Wang, Jian and Kristiansen, Karsten and Wang, Jun},
  year = {2009},
  month = jan,
  journal = {Genome Research},
  volume = {19},
  number = {6},
  pages = {1124--1132},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.088013.108},
  abstract = {Next-generation massively parallel sequencing technologies provide ultrahigh throughput at two orders of magnitude lower unit cost than capillary Sanger sequencing technology. One of the key applications of next-generation sequencing is studying genetic variation between individuals using whole-genome or target region resequencing. Here, we have developed a consensus-calling and SNP-detection method for sequencing-by-synthesis Illumina Genome Analyzer technology. We designed this method by carefully considering the data quality, alignment, and experimental errors common to this technology. All of this information was integrated into a single quality score for each base under Bayesian theory to measure the accuracy of consensus calling. We tested this methodology using a large-scale human resequencing data set of 36\texttimes{} coverage and assembled a high-quality nonrepetitive consensus sequence for 92.25\% of the diploid autosomes and 88.07\% of the haploid X chromosome. Comparison of the consensus sequence with Illumina human 1M BeadChip genotyped alleles from the same DNA sample showed that 98.6\% of the 37,933 genotyped alleles on the X chromosome and 98\% of 999,981 genotyped alleles on autosomes were covered at 99.97\% and 99.84\% consistency, respectively. At a low sequencing depth, we used prior probability of dbSNP alleles and were able to improve coverage of the dbSNP sites significantly as compared to that obtained using a nonimputation model. Our analyses demonstrate that our method has a very low false call rate at any sequencing depth and excellent genome coverage at a high sequencing depth.},
  language = {en},
  pmid = {19420381},
  file = {/home/devan/Zotero/storage/XBA3UM9X/Li et al. - 2009 - SNP detection for massively parallel whole-genome .pdf}
}

@article{liSOAP2ImprovedUltrafast2009,
  title = {{{SOAP2}}: An Improved Ultrafast Tool for Short Read Alignment},
  shorttitle = {{{SOAP2}}},
  author = {Li, Ruiqiang and Yu, Chang and Li, Yingrui and Lam, Tak-Wah and Yiu, Siu-Ming and Kristiansen, Karsten and Wang, Jun},
  year = {2009},
  month = aug,
  journal = {Bioinformatics},
  volume = {25},
  number = {15},
  pages = {1966--1967},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btp336},
  abstract = {Summary: SOAP2 is a significantly improved version of the short oligonucleotide alignment program that both reduces computer memory usage and increases alignment speed at an unprecedented rate. We used a Burrows Wheeler Transformation (BWT) compression index to substitute the seed strategy for indexing the reference sequence in the main memory. We tested it on the whole human genome and found that this new algorithm reduced memory usage from 14.7 to 5.4 GB and improved alignment speed by 20\textendash 30 times. SOAP2 is compatible with both single- and paired-end reads. Additionally, this tool now supports multiple text and compressed file formats. A consensus builder has also been developed for consensus assembly and SNP detection from alignment of short reads on a reference genome.Availability:http://soap.genomics.org.cnContact:soap@genomics.org.cn},
  file = {/home/devan/Zotero/storage/4YJZMMVN/Li et al_2009_SOAP2.pdf;/home/devan/Zotero/storage/BFI36VUU/212427.html}
}

@article{liStatisticalFrameworkSNP2011,
  title = {A Statistical Framework for {{SNP}} Calling, Mutation Discovery, Association Mapping and Population Genetical Parameter Estimation from Sequencing Data},
  author = {Li, Heng},
  year = {2011},
  month = nov,
  journal = {Bioinformatics},
  volume = {27},
  number = {21},
  pages = {2987--2993},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btr509},
  abstract = {Motivation: Most existing methods for DNA sequence analysis rely on accurate sequences or genotypes. However, in applications of the next-generation sequencing (NGS), accurate genotypes may not be easily obtained (e.g. multi-sample low-coverage sequencing or somatic mutation discovery). These applications press for the development of new methods for analyzing sequence data with uncertainty.Results: We present a statistical framework for calling SNPs, discovering somatic mutations, inferring population genetical parameters and performing association tests directly based on sequencing data without explicit genotyping or linkage-based imputation. On real data, we demonstrate that our method achieves comparable accuracy to alternative methods for estimating site allele count, for inferring allele frequency spectrum and for association mapping. We also highlight the necessity of using symmetric datasets for finding somatic mutations and confirm that for discovering rare events, mismapping is frequently the leading source of errors.Availability:http://samtools.sourceforge.netContact:hengli@broadinstitute.org},
  file = {/home/devan/Zotero/storage/M9T8BEKZ/Li - 2011 - A statistical framework for SNP calling, mutation .pdf;/home/devan/Zotero/storage/3EKDJ54V/217423.html}
}

@article{narzisiAccurateNovoTransmitted2014,
  title = {Accurate de Novo and Transmitted Indel Detection in Exome-Capture Data Using Microassembly},
  author = {Narzisi, Giuseppe and O'Rawe, Jason A. and Iossifov, Ivan and Fang, Han and Lee, Yoon-ha and Wang, Zihua and Wu, Yiyang and Lyon, Gholson J. and Wigler, Michael and Schatz, Michael C.},
  year = {2014},
  month = oct,
  journal = {Nature Methods},
  volume = {11},
  number = {10},
  pages = {1033--1036},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/nmeth.3069},
  abstract = {Scalpel combines mapping and assembly to find insertions and deletions in exome sequence data.},
  copyright = {2014 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  language = {en},
  file = {/home/devan/Zotero/storage/Y9BTCC9Z/Narzisi et al. - 2014 - Accurate de novo and transmitted indel detection i.pdf;/home/devan/Zotero/storage/HLQDNPM9/nmeth.html}
}

@article{nielsenSNPCallingGenotype2012,
  title = {{{SNP Calling}}, {{Genotype Calling}}, and {{Sample Allele Frequency Estimation}} from {{New}}-{{Generation Sequencing Data}}},
  author = {Nielsen, Rasmus and Korneliussen, Thorfinn and Albrechtsen, Anders and Li, Yingrui and Wang, Jun},
  year = {2012},
  month = jul,
  journal = {PLOS ONE},
  volume = {7},
  number = {7},
  pages = {e37558},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0037558},
  abstract = {We present a statistical framework for estimation and application of sample allele frequency spectra from New-Generation Sequencing (NGS) data. In this method, we first estimate the allele frequency spectrum using maximum likelihood. In contrast to previous methods, the likelihood function is calculated using a dynamic programming algorithm and numerically optimized using analytical derivatives. We then use a Bayesian method for estimating the sample allele frequency in a single site, and show how the method can be used for genotype calling and SNP calling. We also show how the method can be extended to various other cases including cases with deviations from Hardy-Weinberg equilibrium. We evaluate the statistical properties of the methods using simulations and by application to a real data set.},
  language = {en},
  file = {/home/devan/Zotero/storage/MI8D7UI3/Nielsen et al. - 2012 - SNP Calling, Genotype Calling, and Sample Allele F.pdf}
}

@article{NomenclatureIncompletelySpecified1986,
  title = {Nomenclature for Incompletely Specified Bases in Nucleic Acid Sequences. {{Recommendations}} 1984. {{Nomenclature Committee}} of the {{International Union}} of {{Biochemistry}} ({{NC}}-{{IUB}}).},
  author = {Nomenclature Committee of the International Union of Biochemistry},
  year = {1986},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  volume = {83},
  number = {1},
  pages = {4--8},
  issn = {0027-8424},
  pmcid = {PMC322779},
  pmid = {2417239},
  file = {/home/devan/Zotero/storage/L5BETM2R/1986_Nomenclature for incompletely specified bases in nucleic acid sequences.pdf}
}

@article{nuteScalingStatisticalMultiple2016,
  title = {Scaling Statistical Multiple Sequence Alignment to Large Datasets},
  author = {Nute, Michael and Warnow, Tandy},
  year = {2016},
  month = nov,
  journal = {BMC Genomics},
  volume = {17},
  number = {S10},
  pages = {764},
  issn = {1471-2164},
  doi = {10.1186/s12864-016-3101-8},
  abstract = {Background: Multiple sequence alignment is an important task in bioinformatics, and alignments of large datasets containing hundreds or thousands of sequences are increasingly of interest. While many alignment methods exist, the most accurate alignments are likely to be based on stochastic models where sequences evolve down a tree with substitutions, insertions, and deletions. While some methods have been developed to estimate alignments under these stochastic models, only the Bayesian method BAli-Phy has been able to run on even moderately large datasets, containing 100 or so sequences. A technique to extend BAli-Phy to enable alignments of thousands of sequences could potentially improve alignment and phylogenetic tree accuracy on large-scale data beyond the best-known methods today. Results: We use simulated data with up to 10,000 sequences representing a variety of model conditions, including some that are significantly divergent from the statistical models used in BAli-Phy and elsewhere. We give a method for incorporating BAli-Phy into PASTA and UPP, two strategies for enabling alignment methods to scale to large datasets, and give alignment and tree accuracy results measured against the ground truth from simulations. Comparable results are also given for other methods capable of aligning this many sequences. Conclusions: Extensions of BAli-Phy using PASTA and UPP produce significantly more accurate alignments and phylogenetic trees than the current leading methods.},
  language = {en},
  file = {/home/devan/Zotero/storage/D3G39I4D/Nute and Warnow - 2016 - Scaling statistical multiple sequence alignment to.pdf}
}

@article{oraweAccountingUncertaintyDNA2015,
  title = {Accounting for Uncertainty in {{DNA}} Sequencing Data},
  author = {O'Rawe, Jason A. and Ferson, Scott and Lyon, Gholson J.},
  year = {2015},
  month = feb,
  journal = {Trends in Genetics},
  volume = {31},
  number = {2},
  pages = {61--66},
  issn = {0168-9525},
  doi = {10.1016/j.tig.2014.12.002},
  abstract = {Science is defined in part by an honest exposition of the uncertainties that arise in measurements and propagate through calculations and inferences, so that the reliabilities of its conclusions are made apparent. The recent rapid development of high-throughput DNA sequencing technologies has dramatically increased the number of measurements made at the biochemical and molecular level. These data come from many different DNA-sequencing technologies, each with their own platform-specific errors and biases, which vary widely. Several statistical studies have tried to measure error rates for basic determinations, but there are no general schemes to project these uncertainties so as to assess the surety of the conclusions drawn about genetic, epigenetic, and more general biological questions. We review here the state of uncertainty quantification in DNA sequencing applications, describe sources of error, and propose methods that can be used for accounting and propagating these errors and their uncertainties through subsequent calculations.},
  language = {en},
  keywords = {important,revisit},
  file = {/home/devan/Zotero/storage/TNMFF3W5/O’Rawe et al. - 2015 - Accounting for uncertainty in DNA sequencing data.pdf;/home/devan/Zotero/storage/843YVT3T/S0168952514002091.html}
}

@article{oraweLowConcordanceMultiple2013,
  title = {Low Concordance of Multiple Variant-Calling Pipelines: Practical Implications for Exome and Genome Sequencing},
  shorttitle = {Low Concordance of Multiple Variant-Calling Pipelines},
  author = {O'Rawe, Jason and Jiang, Tao and Sun, Guangqing and Wu, Yiyang and Wang, Wei and Hu, Jingchu and Bodily, Paul and Tian, Lifeng and Hakonarson, Hakon and Johnson, W. Evan and Wei, Zhi and Wang, Kai and Lyon, Gholson J.},
  year = {2013},
  month = mar,
  journal = {Genome Medicine},
  volume = {5},
  number = {3},
  pages = {28},
  issn = {1756-994X},
  doi = {10.1186/gm432},
  abstract = {To facilitate the clinical implementation of genomic medicine by next-generation sequencing, it will be critically important to obtain accurate and consistent variant calls on personal genomes. Multiple software tools for variant calling are available, but it is unclear how comparable these tools are or what their relative merits in real-world scenarios might be.},
  file = {/home/devan/Zotero/storage/UIJTGHY5/O'Rawe et al. - 2013 - Low concordance of multiple variant-calling pipeli.pdf}
}

@article{poonMappingShapesPhylogenetic2013,
  title = {Mapping the {{Shapes}} of {{Phylogenetic Trees}} from {{Human}} and {{Zoonotic RNA Viruses}}},
  author = {Poon, Art F. Y. and Walker, Lorne W. and Murray, Heather and McCloskey, Rosemary M. and Harrigan, P. Richard and Liang, Richard H.},
  year = {2013},
  month = nov,
  journal = {PLOS ONE},
  volume = {8},
  number = {11},
  pages = {e78122},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0078122},
  abstract = {A phylogeny is a tree-based model of common ancestry that is an indispensable tool for studying biological variation. Phylogenies play a special role in the study of rapidly evolving populations such as viruses, where the proliferation of lineages is constantly being shaped by the mode of virus transmission, by adaptation to immune systems, and by patterns of human migration and contact. These processes may leave an imprint on the shapes of virus phylogenies that can be extracted for comparative study; however, tree shapes are intrinsically difficult to quantify. Here we present a comprehensive study of phylogenies reconstructed from 38 different RNA viruses from 12 taxonomic families that are associated with human pathologies. To accomplish this, we have developed a new procedure for studying phylogenetic tree shapes based on the `kernel trick', a technique that maps complex objects into a statistically convenient space. We show that our kernel method outperforms nine different tree balance statistics at correctly classifying phylogenies that were simulated under different evolutionary scenarios. Using the kernel method, we observe patterns in the distribution of RNA virus phylogenies in this space that reflect modes of transmission and pathogenesis. For example, viruses that can establish persistent chronic infections (such as HIV and hepatitis C virus) form a distinct cluster. Although the visibly `star-like' shape characteristic of trees from these viruses has been well-documented, we show that established methods for quantifying tree shape fail to distinguish these trees from those of other viruses. The kernel approach presented here potentially represents an important new tool for characterizing the evolution and epidemiology of RNA viruses.},
  language = {en},
  file = {/home/devan/Zotero/storage/2Q372BM6/Poon et al. - 2013 - Mapping the Shapes of Phylogenetic Trees from Huma.pdf}
}

@article{posada-cespedesVpipeComputationalPipeline2020,
  title = {V-Pipe: A Computational Pipeline for Assessing Viral Genetic Diversity from High-Throughput Sequencing Data},
  shorttitle = {V-Pipe},
  author = {{Posada-C{\'e}spedes}, Susana and Seifert, David and Topolsky, Ivan and Metzner, Karin J. and Beerenwinkel, Niko},
  year = {2020},
  month = jun,
  journal = {bioRxiv},
  pages = {2020.06.09.142919},
  publisher = {{Cold Spring Harbor Laboratory}},
  doi = {10.1101/2020.06.09.142919},
  abstract = {{$<$}h3{$>$}Abstract{$<$}/h3{$>$} {$<$}p{$>$}High-throughput sequencing technologies are used increasingly, not only in viral genomics research but also in clinical surveillance and diagnostics. These technologies facilitate the assessment of the genetic diversity in intra-host virus populations, which affects transmission, virulence, and pathogenesis of viral infections. However, there are two major challenges in analysing viral diversity. First, amplification and sequencing errors confound the identification of true biological variants, and second, the large data volumes represent computational limitations. To support viral high-throughput sequencing studies, we developed V-pipe, a bioinformatics pipeline combining various state-of-the-art statistical models and computational tools for automated end-to-end analyses of raw sequencing reads. V-pipe supports quality control, read mapping and alignment, low-frequency mutation calling, and inference of viral haplotypes. For generating high-quality read alignments, we developed a novel method, called \emph{ngshmmalign}, based on profile hidden Markov models and tailored to small and highly diverse viral genomes. V-pipe also includes benchmarking functionality providing a standardized environment for comparative evaluations of different pipeline configurations. We demonstrate this capability by assessing the impact of three different read aligners (Bowtie 2, BWA MEM, ngshmmalign) and two different variant callers (LoFreq, ShoRAH) on the performance of calling single-nucleotide variants in intra-host virus populations. V-pipe supports various pipeline configurations and is implemented in a modular fashion to facilitate adaptations to the continuously changing technology landscape. V-pipe is freely available at https://github.com/cbg-ethz/V-pipe.{$<$}/p{$>$}},
  chapter = {New Results},
  copyright = {\textcopyright{} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  language = {en},
  file = {/home/devan/Zotero/storage/HHSBKGZR/Posada-Céspedes et al. - 2020 - V-pipe a computational pipeline for assessing vir.pdf;/home/devan/Zotero/storage/JC2XVTAI/2020.06.09.142919v1.html}
}

@article{rambautDynamicNomenclatureProposal2020,
  title = {A Dynamic Nomenclature Proposal for {{SARS}}-{{CoV}}-2 Lineages to Assist Genomic Epidemiology},
  author = {Rambaut, Andrew and Holmes, Edward C. and O'Toole, {\'A}ine and Hill, Verity and McCrone, John T. and Ruis, Christopher and {du Plessis}, Louis and Pybus, Oliver G.},
  year = {2020},
  month = jul,
  journal = {Nature Microbiology},
  issn = {2058-5276},
  doi = {10.1038/s41564-020-0770-5},
  language = {en},
  keywords = {clustering,covid,data/code available,important,manualGeo,pangolin},
  file = {/home/devan/Zotero/storage/N3FHIXSP/Rambaut et al. - 2020 - A dynamic nomenclature proposal for SARS-CoV-2 lin.pdf}
}

@article{richterichEstimationErrorsRaw1998,
  title = {Estimation of {{Errors}} in ``{{Raw}}'' {{DNA Sequences}}: {{A Validation Study}}},
  shorttitle = {Estimation of {{Errors}} in ``{{Raw}}'' {{DNA Sequences}}},
  author = {Richterich, Peter},
  year = {1998},
  month = jan,
  journal = {Genome Research},
  volume = {8},
  number = {3},
  pages = {251--259},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.8.3.251},
  abstract = {As DNA sequencing is performed more and more in a mass-production-like manner, efficient quality control measures become increasingly important for process control, but so also does the ability to compare different methods and projects. One of the fundamental quality measures in sequencing projects is the position-specific error probability at all bases in each individual sequence. Accurate prediction of base-specific error rates from ``raw'' sequence data would allow immediate quality control as well as benchmarking different methods and projects while avoiding the inefficiencies and time delays associated with resequencing and assessments after ``finishing'' a sequence. The program PHRED provides base-specific quality scores that are logarythmically related to error probabilities. This study assessed the accuracy of PHRED's error-rate prediction by analyzing sequencing projects from six different large-scale sequencing laboratories. All projects used four-color fluorescent sequencing, but the sequencing methods used varied widely between the different projects. The results indicate that the error-rate predictions such as those given by PHRED can be highly accurate for a large variety of different sequencing methods as well as over a wide range of sequence quality.},
  language = {en},
  pmid = {9521928},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/8L3IMF4M/Richterich - 1998 - Estimation of Errors in “Raw” DNA Sequences A Val.pdf;/home/devan/Zotero/storage/NPFKYXK7/251.html}
}

@article{robaskyRoleReplicatesError2014,
  title = {The Role of Replicates for Error Mitigation in Next-Generation Sequencing},
  author = {Robasky, Kimberly and Lewis, Nathan E. and Church, George M.},
  year = {2014},
  month = jan,
  journal = {Nature Reviews Genetics},
  volume = {15},
  number = {1},
  pages = {56--62},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg3655},
  abstract = {Next-generation sequencing for variant identification is now becoming widespread, although pipelines have not yet been optimized. In this Perspective article, the authors discuss ways to minimize erroneous variant calls, in particular, by using replicates.},
  copyright = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  language = {en},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/SKYAYW25/Robasky et al. - 2014 - The role of replicates for error mitigation in nex.pdf}
}

@article{robinsonComparisonPhylogeneticTrees1981,
  title = {Comparison of Phylogenetic Trees},
  author = {Robinson, D. F. and Foulds, L. R.},
  year = {1981},
  month = feb,
  journal = {Mathematical Biosciences},
  volume = {53},
  number = {1},
  pages = {131--147},
  issn = {0025-5564},
  doi = {10.1016/0025-5564(81)90043-2},
  abstract = {A metric on general phylogenetic trees is presented. This extends the work of most previous authors, who constructed metrics for binary trees. The metric presented in this paper makes possible the comparison of the many nonbinary phylogenetic trees appearing in the literature. This provides an objective procedure for comparing the different methods for constructing phylogenetic trees. The metric is based on elementary operations which transform one tree into another. Various results obtained in applying these operations are given. They enable the distance between any pair of trees to be calculated efficiently. This generalizes previous work by Bourque to the case where interior vertices can be labeled, and labels may contain more than one element or may be empty.},
  language = {en},
  file = {/home/devan/Zotero/storage/6I3726XJ/Robinson and Foulds - 1981 - Comparison of phylogenetic trees.pdf;/home/devan/Zotero/storage/ZAMDICII/0025556481900432.html}
}

@inproceedings{robinsonComparisonWeightedLabelled1979,
  title = {Comparison of Weighted Labelled Trees},
  booktitle = {Combinatorial {{Mathematics VI}}},
  author = {Robinson, D. F. and Foulds, L. R.},
  editor = {Horadam, A. F. and Wallis, W. D.},
  year = {1979},
  series = {Lecture {{Notes}} in {{Mathematics}}},
  pages = {119--126},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0102690},
  abstract = {The results in a previous paper on the comparison of (unweighted) labelled trees are extended to the comparison of weighted labelled trees. An elementary operation is introduced which enables one to transform one weighted labelled tree into another. The operation makes it possible to compare different trees in a quantitative way in the sense of defining a "distance" between them. An application to a problem in molecular evolution is given.},
  isbn = {978-3-540-34857-3},
  language = {en},
  keywords = {Base Change,Edge Weight,Elementary Operation,Label Tree,Pendant Vertex},
  file = {/home/devan/Zotero/storage/3XRGA2ZJ/Robinson_Foulds_1979_Comparison of weighted labelled trees.pdf}
}

@article{rossOncoNEMInferringTumor2016,
  title = {{{OncoNEM}}: Inferring Tumor Evolution from Single-Cell Sequencing Data},
  shorttitle = {{{OncoNEM}}},
  author = {Ross, Edith M. and Markowetz, Florian},
  year = {2016},
  month = dec,
  journal = {Genome Biology},
  volume = {17},
  number = {1},
  pages = {69},
  issn = {1474-760X},
  doi = {10.1186/s13059-016-0929-9},
  abstract = {Single-cell sequencing promises a high-resolution view of genetic heterogeneity and clonal evolution in cancer. However, methods to infer tumor evolution from single-cell sequencing data lag behind methods developed for bulk-sequencing data. Here, we present OncoNEM, a probabilistic method for inferring intra-tumor evolutionary lineage trees from somatic single nucleotide variants of single cells. OncoNEM identifies homogeneous cellular subpopulations and infers their genotypes as well as a tree describing their evolutionary relationships. In simulation studies, we assess OncoNEM's robustness and benchmark its performance against competing methods. Finally, we show its applicability in case studies of muscle-invasive bladder cancer and essential thrombocythemia.},
  language = {en},
  file = {/home/devan/Zotero/storage/UJWE5AHI/Ross and Markowetz - 2016 - OncoNEM inferring tumor evolution from single-cel.pdf}
}

@article{sagulenkoTreeTimeMaximumlikelihoodPhylodynamic2018,
  title = {{{TreeTime}}: {{Maximum}}-Likelihood Phylodynamic Analysis},
  shorttitle = {{{TreeTime}}},
  author = {Sagulenko, Pavel and Puller, Vadim and Neher, Richard A},
  year = {2018},
  month = jan,
  journal = {Virus Evolution},
  volume = {4},
  number = {1},
  pages = {vex042},
  issn = {2057-1577},
  doi = {10.1093/ve/vex042},
  abstract = {Mutations that accumulate in the genome of cells or viruses can be used to infer their evolutionary history. In the case of rapidly evolving organisms, genomes can reveal their detailed spatiotemporal spread. Such phylodynamic analyses are particularly useful to understand the epidemiology of rapidly evolving viral pathogens. As the number of genome sequences available for different pathogens has increased dramatically over the last years, phylodynamic analysis with traditional methods becomes challenging as these methods scale poorly with growing datasets. Here, we present TreeTime, a Python-based framework for phylodynamic analysis using an approximate Maximum Likelihood approach. TreeTime can estimate ancestral states, infer evolution models, reroot trees to maximize temporal signals, estimate molecular clock phylogenies and population size histories. The runtime of TreeTime scales linearly with dataset size.},
  pmcid = {PMC5758920},
  pmid = {29340210},
  file = {/home/devan/Zotero/storage/37UJF3IK/Sagulenko et al_2018_TreeTime.pdf}
}

@article{schneiderConsensusSequenceZen2002,
  title = {Consensus {{Sequence Zen}}},
  author = {Schneider, Thomas D.},
  year = {2002},
  journal = {Applied bioinformatics},
  volume = {1},
  number = {3},
  pages = {111--119},
  issn = {1175-5636},
  abstract = {Consensus sequences are widely used in molecular biology but they have many flaws. As a result, binding sites of proteins and other molecules are missed during studies of genetic sequences and important biological effects cannot be seen. Information theory provides a mathematically robust way to avoid consensus sequences. Instead of using consensus sequences, sequence conservation can be quantitatively presented in bits of information by using sequence logo graphics to represent the average of a set of sites and sequence walker graphics to represent individual sites., ``All models are wrong but some are useful.''\textemdash{} George E. P. Box (Box, 1979)},
  pmcid = {PMC1852464},
  pmid = {15130839},
  keywords = {important,logos},
  file = {/home/devan/Zotero/storage/AI5P4VDA/Schneider - 2002 - Consensus Sequence Zen.pdf}
}

@article{schneiderInformationContentBinding1986,
  title = {Information Content of Binding Sites on Nucleotide Sequences},
  author = {Schneider, Thomas D. and Stormo, Gary D. and Gold, Larry and Ehrenfeucht, Andrzej},
  year = {1986},
  month = apr,
  journal = {Journal of Molecular Biology},
  volume = {188},
  number = {3},
  pages = {415--431},
  issn = {00222836},
  doi = {10.1016/0022-2836(86)90165-8},
  language = {en},
  file = {/home/devan/Zotero/storage/QR5SVY6E/Schneider et al. - 1986 - Information content of binding sites on nucleotide.pdf}
}

@article{schneiderSequenceLogosNew1990,
  title = {Sequence Logos: A New Way to Display Consensus Sequences},
  shorttitle = {Sequence Logos},
  author = {Schneider, Thomas D. and Stephens, R.Michael},
  year = {1990},
  journal = {Nucleic Acids Research},
  volume = {18},
  number = {20},
  pages = {6097--6100},
  issn = {0305-1048, 1362-4962},
  doi = {10.1093/nar/18.20.6097},
  abstract = {A graphical method is presented for displaying the patterns in a set of aligned sequences. The characters representing the sequence are stacked on top of each other for each position in the aligned sequences. The height of each letter is made proportional to Its frequency, and the letters are sorted so the most common one is on top. The height of the entire stack is then adjusted to signify the information content of the sequences at that position. From these 'sequence logos', one can determine not only the consensus sequence but also the relative frequency of bases and the information content (measured In bits) at every position in a site or sequence. The logo displays both significant residues and subtle sequence patterns.},
  language = {en},
  file = {/home/devan/Zotero/storage/KNU5BMBQ/Schneider and Stephens - 1990 - Sequence logos a new way to display consensus seq.pdf}
}

@article{SimulationComparisonPhylogeny1994,
  title = {A Simulation Comparison of Phylogeny Algorithms under Equal and Unequal Evolutionary Rates.},
  year = {1994},
  month = may,
  journal = {Molecular Biology and Evolution},
  issn = {1537-1719},
  doi = {10.1093/oxfordjournals.molbev.a040126},
  language = {en},
  file = {/home/devan/Zotero/storage/2FLFFRVU/1994 - A simulation comparison of phylogeny algorithms un.pdf}
}

@article{siposPhyloSimMonteCarlo2011,
  title = {{{PhyloSim}} - {{Monte Carlo}} Simulation of Sequence Evolution in the {{R}} Statistical Computing Environment},
  author = {Sipos, Botond and Massingham, Tim and Jordan, Gregory E. and Goldman, Nick},
  year = {2011},
  month = dec,
  journal = {BMC Bioinformatics},
  volume = {12},
  number = {1},
  pages = {1--6},
  publisher = {{BioMed Central}},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-12-104},
  abstract = {The Monte Carlo simulation of sequence evolution is routinely used to assess the performance of phylogenetic inference methods and sequence alignment algorithms. Progress in the field of molecular evolution fuels the need for more realistic and hence more complex simulations, adapted to particular situations, yet current software makes unreasonable assumptions such as homogeneous substitution dynamics or a uniform distribution of indels across the simulated sequences. This calls for an extensible simulation framework written in a high-level functional language, offering new functionality and making it easy to incorporate further complexity. PhyloSim is an extensible framework for the Monte Carlo simulation of sequence evolution, written in R, using the Gillespie algorithm to integrate the actions of many concurrent processes such as substitutions, insertions and deletions. Uniquely among sequence simulation tools, PhyloSim can simulate arbitrarily complex patterns of rate variation and multiple indel processes, and allows for the incorporation of selective constraints on indel events. User-defined complex patterns of mutation and selection can be easily integrated into simulations, allowing PhyloSim to be adapted to specific needs. Close integration with R and the wide range of features implemented offer unmatched flexibility, making it possible to simulate sequence evolution under a wide range of realistic settings. We believe that PhyloSim will be useful to future studies involving simulated alignments.},
  copyright = {2011 Sipos et al; licensee BioMed Central Ltd.},
  language = {en},
  file = {/home/devan/Zotero/storage/GUUQEGLW/Sipos et al_2011_PhyloSim - Monte Carlo simulation of sequence evolution in the R statistical.pdf;/home/devan/Zotero/storage/E9CX7QZP/1471-2105-12-104.html}
}

@article{skotteAssociationTestingNextGeneration2012,
  title = {Association {{Testing}} for {{Next}}-{{Generation Sequencing Data Using Score Statistics}}},
  author = {Skotte, Line and Korneliussen, Thorfinn Sand and Albrechtsen, Anders},
  year = {2012},
  journal = {Genetic Epidemiology},
  volume = {36},
  number = {5},
  pages = {430--437},
  issn = {1098-2272},
  doi = {10.1002/gepi.21636},
  abstract = {The advances in sequencing technology have made large-scale sequencing studies for large cohorts feasible. Often, the primary goal for large-scale studies is to identify genetic variants associated with a disease or other phenotypes. Even when deep sequencing is performed, there will be many sites where there is not enough data to call genotypes accurately. Ignoring the genotype classification uncertainty by basing subsequent analyses on called genotypes leads to a loss in power. Additionally, using called genotypes can lead to spurious association signals. Some methods taking the uncertainty of genotype calls into account have been proposed; most require numerical optimization which for large-scale data is not always computationally feasible. We show that using a score statistic for the joint likelihood of observed phenotypes and observed sequencing data provides an attractive approach to association testing for next-generation sequencing data. The joint model accounts for the genotype classification uncertainty via the posterior probabilities of the genotypes given the observed sequencing data, which gives the approach higher power than methods based on called genotypes. This strategy remains computationally feasible due to the use of score statistics. As part of the joint likelihood, we model the distribution of the phenotypes using a generalized linear model framework, which works for both quantitative and discrete phenotypes. Thus, the method presented here is applicable to case-control studies as well as mapping of quantitative traits. The model allows additional covariates that enable correction for confounding factors such as population stratification or cohort effects. Genet. Epidemiol. 36:430-437, 2012. \textcopyright{} 2012 Wiley Periodicals, Inc.},
  copyright = {\textcopyright{} 2012 Wiley Periodicals, Inc.},
  language = {en},
  keywords = {revisit},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/gepi.21636},
  file = {/home/devan/Zotero/storage/N2CRT7XC/Skotte et al. - 2012 - Association Testing for Next-Generation Sequencing.pdf}
}

@article{skotteEstimatingIndividualAdmixture2013,
  title = {Estimating {{Individual Admixture Proportions}} from {{Next Generation Sequencing Data}}},
  author = {Skotte, Line and Korneliussen, Thorfinn Sand and Albrechtsen, Anders},
  year = {2013},
  month = nov,
  journal = {Genetics},
  volume = {195},
  number = {3},
  pages = {693--702},
  issn = {0016-6731, 1943-2631},
  doi = {10.1534/genetics.113.154138},
  abstract = {Inference of population structure and individual ancestry is important both for population genetics and for association studies. With next generation sequencing technologies it is possible to obtain genetic data for all accessible genetic variations in the genome. Existing methods for admixture analysis rely on known genotypes. However, individual genotypes cannot be inferred from low-depth sequencing data without introducing errors. This article presents a new method for inferring an individual's ancestry that takes the uncertainty introduced in next generation sequencing data into account. This is achieved by working directly with genotype likelihoods that contain all relevant information of the unobserved genotypes. Using simulations as well as publicly available sequencing data, we demonstrate that the presented method has great accuracy even for very low-depth data. At the same time, we demonstrate that applying existing methods to genotypes called from the same data can introduce severe biases. The presented method is implemented in the NGSadmix software available at http://www.popgen.dk/software.},
  language = {en},
  file = {/home/devan/Zotero/storage/VBDDBKH5/Skotte et al. - 2013 - Estimating Individual Admixture Proportions from N.pdf}
}

@article{smithInformationTheoreticGeneralized2020,
  title = {Information Theoretic Generalized {{Robinson}}\textendash{{Foulds}} Metrics for Comparing Phylogenetic Trees},
  author = {Smith, Martin R},
  editor = {Schwartz, Russell},
  year = {2020},
  month = dec,
  journal = {Bioinformatics},
  volume = {36},
  number = {20},
  pages = {5007--5013},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btaa614},
  abstract = {Motivation: The Robinson\textendash Foulds (RF) metric is widely used by biologists, linguists and chemists to quantify similarity between pairs of phylogenetic trees. The measure tallies the number of bipartition splits that occur in both trees\textemdash but this conservative approach ignores potential similarities between almost-identical splits, with undesirable consequences. `Generalized' RF metrics address this shortcoming by pairing splits in one tree with similar splits in the other. Each pair is assigned a similarity score, the sum of which enumerates the similarity between two trees. The challenge lies in quantifying split similarity: existing definitions lack a principled statistical underpinning, resulting in misleading tree distances that are difficult to interpret. Here, I propose probabilistic measures of split similarity, which allow tree similarity to be measured in natural units (bits).},
  language = {en},
  file = {/home/devan/Zotero/storage/H3A8BB2W/Smith - 2020 - Information theoretic generalized Robinson–Foulds .pdf}
}

@article{stamatakisRAxMLVersionTool2014,
  title = {{{RAxML}} Version 8: A Tool for Phylogenetic Analysis and Post-Analysis of Large Phylogenies},
  shorttitle = {{{RAxML}} Version 8},
  author = {Stamatakis, Alexandros},
  year = {2014},
  month = may,
  journal = {Bioinformatics},
  volume = {30},
  number = {9},
  pages = {1312--1313},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btu033},
  abstract = {Motivation: Phylogenies are increasingly used in all fields of medical and biological research. Moreover, because of the next-generation sequencing revolution, datasets used for conducting phylogenetic analyses grow at an unprecedented pace. RAxML (Randomized Axelerated Maximum Likelihood) is a popular program for phylogenetic analyses of large datasets under maximum likelihood. Since the last RAxML paper in 2006, it has been continuously maintained and extended to accommodate the increasingly growing input datasets and to serve the needs of the user community.Results: I present some of the most notable new features and extensions of RAxML, such as a substantial extension of substitution models and supported data types, the introduction of SSE3, AVX and AVX2 vector intrinsics, techniques for reducing the memory requirements of the code and a plethora of operations for conducting post-analyses on sets of trees. In addition, an up-to-date 50-page user manual covering all new RAxML options is available.Availability and implementation: The code is available under GNU GPL at https://github.com/stamatak/standard-RAxML.Contact:alexandros.stamatakis@h-its.orgSupplementary information:Supplementary data are available at Bioinformatics online.},
  file = {/home/devan/Zotero/storage/35GH4XDW/Stamatakis_2014_RAxML version 8.pdf;/home/devan/Zotero/storage/EIPFNAMJ/238053.html}
}

@article{stormoUsePerceptronAlgorithm1982,
  title = {Use of the 'perceptron' Algorithm to Distinguish Translational Initiation Sites in {{E}}. Coli},
  author = {Stormo, Gary D and Schneider, Thomas D and Gold, Larry and Ehrenfeucht, Andrzej},
  year = {1982},
  journal = {Nucleic Acids Research},
  volume = {10},
  number = {9},
  pages = {16},
  abstract = {We have used a "Perceptron" algorithm to find a weighting function which distinguishes E\_. coli translatlonal Initiation sites from all other sites in a library of over 78,000 nucleotides of mRNA sequence. The "Perceptron" examined sequences as linear representations. The "Perceptron" is more successful at finding gene beginnings than our previous searches using "rules" (see previous paper). We note that the weighting function can find translational initiation sites within sequences that were not included In the training set.},
  language = {en},
  file = {/home/devan/Zotero/storage/9CY9RA4D/Stormo et al. - Department of Molecular, Cellular and Developmenta.pdf}
}

@article{trapnellDifferentialGeneTranscript2012,
  title = {Differential Gene and Transcript Expression Analysis of {{RNA}}-Seq Experiments with {{TopHat}} and {{Cufflinks}}},
  author = {Trapnell, Cole and Roberts, Adam and Goff, Loyal and Pertea, Geo and Kim, Daehwan and Kelley, David R. and Pimentel, Harold and Salzberg, Steven L. and Rinn, John L. and Pachter, Lior},
  year = {2012},
  month = mar,
  journal = {Nature Protocols},
  volume = {7},
  number = {3},
  pages = {562--578},
  publisher = {{Nature Publishing Group}},
  issn = {1750-2799},
  doi = {10.1038/nprot.2012.016},
  abstract = {Recent advances in high-throughput cDNA sequencing (RNA-seq) can reveal new genes and splice variants and quantify expression genome-wide in a single assay. The volume and complexity of data from RNA-seq experiments necessitate scalable, fast and mathematically principled analysis software. TopHat and Cufflinks are free, open-source software tools for gene discovery and comprehensive expression analysis of high-throughput mRNA sequencing (RNA-seq) data. Together, they allow biologists to identify new genes and new splice variants of known ones, as well as compare gene and transcript expression under two or more conditions. This protocol describes in detail how to use TopHat and Cufflinks to perform such analyses. It also covers several accessory tools and utilities that aid in managing data, including CummeRbund, a tool for visualizing RNA-seq analysis results. Although the procedure assumes basic informatics skills, these tools assume little to no background with RNA-seq analysis and are meant for novices and experts alike. The protocol begins with raw sequencing reads and produces a transcriptome assembly, lists of differentially expressed and regulated genes and transcripts, and publication-quality visualizations of analysis results. The protocol's execution time depends on the volume of transcriptome sequencing data and available computing resources but takes less than 1 d of computer time for typical experiments and {$\sim$}1 h of hands-on time.},
  copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  language = {en},
  keywords = {Cufflinks,CummeRbund,R,revisit,TopHat},
  file = {/home/devan/Zotero/storage/54DWCLNU/Trapnell et al. - 2012 - Differential gene and transcript expression analys.pdf;/home/devan/Zotero/storage/9CFX8Y2A/nprot.2012.html}
}

@article{turakhiaStabilitySARSCoV2Phylogenies2020,
  title = {Stability of {{SARS}}-{{CoV}}-2 Phylogenies},
  author = {Turakhia, Yatish and Maio, Nicola De and Thornlow, Bryan and Gozashti, Landen and Lanfear, Robert and Walker, Conor R. and Hinrichs, Angie S. and Fernandes, Jason D. and Borges, Rui and Slodkowicz, Greg and Weilguny, Lukas and Haussler, David and Goldman, Nick and {Corbett-Detig}, Russell},
  year = {2020},
  month = nov,
  journal = {PLOS Genetics},
  volume = {16},
  number = {11},
  pages = {e1009175},
  publisher = {{Public Library of Science}},
  issn = {1553-7404},
  doi = {10.1371/journal.pgen.1009175},
  abstract = {The SARS-CoV-2 pandemic has led to unprecedented, nearly real-time genetic tracing due to the rapid community sequencing response. Researchers immediately leveraged these data to infer the evolutionary relationships among viral samples and to study key biological questions, including whether host viral genome editing and recombination are features of SARS-CoV-2 evolution. This global sequencing effort is inherently decentralized and must rely on data collected by many labs using a wide variety of molecular and bioinformatic techniques. There is thus a strong possibility that systematic errors associated with lab\textemdash or protocol\textemdash specific practices affect some sequences in the repositories. We find that some recurrent mutations in reported SARS-CoV-2 genome sequences have been observed predominantly or exclusively by single labs, co-localize with commonly used primer binding sites and are more likely to affect the protein-coding sequences than other similarly recurrent mutations. We show that their inclusion can affect phylogenetic inference on scales relevant to local lineage tracing, and make it appear as though there has been an excess of recurrent mutation or recombination among viral lineages. We suggest how samples can be screened and problematic variants removed, and we plan to regularly inform the scientific community with our updated results as more SARS-CoV-2 genome sequences are shared (https://virological.org/t/issues-with-sars-cov-2-sequencing-data/473 and https://virological.org/t/masking-strategies-for-sars-cov-2-alignments/480). We also develop tools for comparing and visualizing differences among very large phylogenies and we show that consistent clade- and tree-based comparisons can be made between phylogenies produced by different groups. These will facilitate evolutionary inferences and comparisons among phylogenies produced for a wide array of purposes. Building on the SARS-CoV-2 Genome Browser at UCSC, we present a toolkit to compare, analyze and combine SARS-CoV-2 phylogenies, find and remove potential sequencing errors and establish a widely shared, stable clade structure for a more accurate scientific inference and discourse.},
  language = {en},
  keywords = {Alleles,Genomics,Microbial mutation,Phylogenetic analysis,Phylogenetics,SARS CoV 2,Trees,Viral evolution},
  file = {/home/devan/Zotero/storage/U7TM9WJU/Turakhia et al. - 2020 - Stability of SARS-CoV-2 phylogenies.pdf;/home/devan/Zotero/storage/6IZWYR9F/article.html}
}

@article{vanderauweraFastQDataHigh2013,
  title = {From {{FastQ}} Data to High Confidence Variant Calls: The {{Genome Analysis Toolkit}} Best Practices Pipeline},
  shorttitle = {From {{FastQ}} Data to High Confidence Variant Calls},
  author = {{Van der Auwera}, Geraldine A. and Carneiro, Mauricio O. and Hartl, Chris and Poplin, Ryan and {del Angel}, Guillermo and {Levy-Moonshine}, Ami and Jordan, Tadeusz and Shakir, Khalid and Roazen, David and Thibault, Joel and Banks, Eric and Garimella, Kiran V. and Altshuler, David and Gabriel, Stacey and DePristo, Mark A.},
  year = {2013},
  month = oct,
  journal = {Current protocols in bioinformatics / editoral board, Andreas D. Baxevanis ... [et al.]},
  volume = {11},
  number = {1110},
  pages = {11.10.1-11.10.33},
  issn = {1934-3396},
  doi = {10.1002/0471250953.bi1110s43},
  abstract = {This unit describes how to use BWA and the Genome Analysis Toolkit (GATK) to map genome sequencing data to a reference and produce high-quality variant calls that can be used in downstream analyses. The complete workflow includes the core NGS data processing steps that are necessary to make the raw data suitable for analysis by the GATK, as well as the key methods involved in variant discovery using the GATK.},
  pmcid = {PMC4243306},
  pmid = {25431634},
  file = {/home/devan/Zotero/storage/ZW6J8XF2/Van der Auwera et al. - 2013 - From FastQ data to high confidence variant calls .pdf}
}

@article{vieiraEstimatingInbreedingCoefficients2013,
  title = {Estimating Inbreeding Coefficients from {{NGS}} Data: {{Impact}} on Genotype Calling and Allele Frequency Estimation},
  shorttitle = {Estimating Inbreeding Coefficients from {{NGS}} Data},
  author = {Vieira, Filipe G. and Fumagalli, Matteo and Albrechtsen, Anders and Nielsen, Rasmus},
  year = {2013},
  month = jan,
  journal = {Genome Research},
  volume = {23},
  number = {11},
  pages = {1852--1861},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.157388.113},
  abstract = {Most methods for next-generation sequencing (NGS) data analyses incorporate information regarding allele frequencies using the assumption of Hardy\textendash Weinberg equilibrium (HWE) as a prior. However, many organisms including those that are domesticated, partially selfing, or with asexual life cycles show strong deviations from HWE. For such species, and specially for low-coverage data, it is necessary to obtain estimates of inbreeding coefficients (F) for each individual before calling genotypes. Here, we present two methods for estimating inbreeding coefficients from NGS data based on an expectation-maximization (EM) algorithm. We assess the impact of taking inbreeding into account when calling genotypes or estimating the site frequency spectrum (SFS), and demonstrate a marked increase in accuracy on low-coverage highly inbred samples. We demonstrate the applicability and efficacy of these methods in both simulated and real data sets.},
  language = {en},
  pmid = {23950147},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/LT3MJTBF/Vieira et al. - 2013 - Estimating inbreeding coefficients from NGS data .pdf}
}

@article{wallEstimatingGenotypeError2014,
  title = {Estimating Genotype Error Rates from High-Coverage next-Generation Sequence Data},
  author = {Wall, Jeffrey D. and Tang, Ling Fung and Zerbe, Brandon and Kvale, Mark N. and Kwok, Pui-Yan and Schaefer, Catherine and Risch, Neil},
  year = {2014},
  month = nov,
  journal = {Genome Research},
  volume = {24},
  number = {11},
  pages = {1734--1739},
  issn = {1088-9051},
  doi = {10.1101/gr.168393.113},
  abstract = {Exome and whole-genome sequencing studies are becoming increasingly common, but little is known about the accuracy of the genotype calls made by the commonly used platforms. Here we use replicate high-coverage sequencing of blood and saliva DNA samples from four European-American individuals to estimate lower bounds on the error rates of Complete Genomics and Illumina HiSeq whole-genome and whole-exome sequencing. Error rates for nonreference genotype calls range from 0.1\% to 0.6\%, depending on the platform and the depth of coverage. Additionally, we found (1) no difference in the error profiles or rates between blood and saliva samples; (2) Complete Genomics sequences had substantially higher error rates than Illumina sequences had; (3) error rates were higher (up to 6\%) for rare or unique variants; (4) error rates generally declined with genotype quality (GQ) score, but in a nonlinear fashion for the Illumina data, likely due to loss of specificity of GQ scores greater than 60; and (5) error rates increased with increasing depth of coverage for the Illumina data. These findings, especially (3)\textendash (5), suggest that caution should be taken in interpreting the results of next-generation sequencing-based association studies, and even more so in clinical application of this technology in the absence of validation by other more robust sequencing or genotyping methods.},
  pmcid = {PMC4216915},
  pmid = {25304867},
  file = {/home/devan/Zotero/storage/6BV6QRLT/Wall et al. - 2014 - Estimating genotype error rates from high-coverage.pdf}
}

@article{weiSNVerStatisticalTool2011,
  title = {{{SNVer}}: A Statistical Tool for Variant Calling in Analysis of Pooled or Individual next-Generation Sequencing Data},
  shorttitle = {{{SNVer}}},
  author = {Wei, Zhi and Wang, Wei and Hu, Pingzhao and Lyon, Gholson J. and Hakonarson, Hakon},
  year = {2011},
  month = oct,
  journal = {Nucleic Acids Research},
  volume = {39},
  number = {19},
  pages = {e132},
  issn = {1362-4962},
  doi = {10.1093/nar/gkr599},
  abstract = {We develop a statistical tool SNVer for calling common and rare variants in analysis of pooled or individual next-generation sequencing (NGS) data. We formulate variant calling as a hypothesis testing problem and employ a binomial-binomial model to test the significance of observed allele frequency against sequencing error. SNVer reports one single overall P-value for evaluating the significance of a candidate locus being a variant based on which multiplicity control can be obtained. This is particularly desirable because tens of thousands loci are simultaneously examined in typical NGS experiments. Each user can choose the false-positive error rate threshold he or she considers appropriate, instead of just the dichotomous decisions of whether to 'accept or reject the candidates' provided by most existing methods. We use both simulated data and real data to demonstrate the superior performance of our program in comparison with existing methods. SNVer runs very fast and can complete testing 300 K loci within an hour. This excellent scalability makes it feasible for analysis of whole-exome sequencing data, or even whole-genome sequencing data using high performance computing cluster. SNVer is freely available at http://snver.sourceforge.net/.},
  language = {eng},
  pmcid = {PMC3201884},
  pmid = {21813454},
  keywords = {Gene Frequency,Genetic Variation,High-Throughput Nucleotide Sequencing,Models; Statistical,Polymorphism; Single Nucleotide,Software},
  file = {/home/devan/Zotero/storage/JNA76B6X/Wei et al_2011_SNVer.pdf}
}

@article{wrobelStatisticalMeasuresUncertainty2008,
  title = {Statistical Measures of Uncertainty for Branches in Phylogenetic Trees Inferred from Molecular Sequences by Using Model-Based Methods},
  author = {Wr{\'o}bel, Borys},
  year = {2008},
  month = mar,
  journal = {Journal of Applied Genetics},
  volume = {49},
  number = {1},
  pages = {49--67},
  issn = {1234-1983, 2190-3883},
  doi = {10.1007/BF03195249},
  abstract = {In recent years, the emphasis of theoretical work on phylogenetic inference has shifted from the development of new tree inference methods to the development of methods to measure the statistical support for the topologies. This paper reviews 3 approaches to assign support values to branches in trees obtained in the analysis of molecular sequences: the bootstrap, the Bayesian posterior probabilities for clades, and the interior branch tests. In some circumstances, these methods give different answers. It should not be surprising: their assumptions are different. Thus the interior branch tests assume that a given topology is true and only consider if a particular branch length is longer than zero. If a tree is incorrect, a wrong branch (a low bootstrap or Bayesian support may be an indication) may have a non-zero length. If the substitution model is oversimplified, the length of a branch may be overestimated, and the Bayesian support for the branch may be inflated. The bootstrap, on the other hand, approximates the variance of the data under the real model of sequence evolution, because it involves direct resampling from this data. Thus the discrepancy between the Bayesian support and the bootstrap support may signal model inaccuracy. In practical application, use of all 3 methods is recommended, and if discrepancies are observed, then a careful analysis of their potential origins should be made.},
  language = {en},
  file = {/home/devan/Zotero/storage/ZXKERDVN/Wróbel - 2008 - Statistical measures of uncertainty for branches i.pdf}
}

@article{wuEstimatingErrorModels2017,
  title = {Estimating Error Models for Whole Genome Sequencing Using Mixtures of {{Dirichlet}}-Multinomial Distributions},
  author = {Wu, Steven H and Schwartz, Rachel S and Winter, David J and Conrad, Donald F and Cartwright, Reed A},
  year = {2017},
  month = aug,
  journal = {Bioinformatics},
  volume = {33},
  number = {15},
  pages = {2322--2329},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btx133},
  abstract = {Accurate identification of genotypes is an essential part of the analysis of genomic data, including in identification of sequence polymorphisms, linking mutations with disease and determining mutation rates. Biological and technical processes that adversely affect genotyping include copy-number-variation, paralogous sequences, library preparation, sequencing error and reference-mapping biases, among others.We modeled the read depth for all data as a mixture of Dirichlet-multinomial distributions, resulting in significant improvements over previously used models. In most cases the best model was comprised of two distributions. The major-component distribution is similar to a binomial distribution with low error and low reference bias. The minor-component distribution is overdispersed with higher error and reference bias. We also found that sites fitting the minor component are enriched for copy number variants and low complexity regions, which can produce erroneous genotype calls. By removing sites that do not fit the major component, we can improve the accuracy of genotype calls.Methods and data files are available at https://github.com/CartwrightLab/WuEtAl2017/ (doi:10.5281/zenodo.256858).Supplementary data is available at Bioinformatics online.},
  keywords = {revisit},
  file = {/home/devan/Zotero/storage/ERDSQX8J/Wu et al. - 2017 - Estimating error models for whole genome sequencin.pdf;/home/devan/Zotero/storage/MCGNSMKX/3071980.html}
}

@article{yandellBeginnerGuideEukaryotic2012,
  title = {A Beginner's Guide to Eukaryotic Genome Annotation},
  author = {Yandell, Mark and Ence, Daniel},
  year = {2012},
  month = may,
  journal = {Nature Reviews Genetics},
  volume = {13},
  number = {5},
  pages = {329--342},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg3174},
  abstract = {Sequencing costs have fallen so dramatically that a single laboratory can now afford to sequence even large genomes.Genome annotation pipelines synthesize alignment-based evidence with ab initio gene predictions to obtain a final set of gene annotations.The exotic nature of many of the genomes that are currently being sequenced complicates annotation efforts.Genome annotation has moved beyond merely identifying protein-coding genes to include the annotation of transposons, regulatory regions, pseudogenes and non-coding RNA genes.Another new challenge is the need to incorporate RNA-seq data into the annotation process.Annotation quality control and management are becoming major bottlenecks.Periodic updates to the annotations to every genome are necessary as new data and techniques become available.Incorrect and incomplete annotations poison every experiment that makes use of them. Providing accurate and up-to-date annotations is therefore essential.},
  copyright = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  language = {en},
  file = {/home/devan/Zotero/storage/28ZRJCRQ/Yandell and Ence - 2012 - A beginner's guide to eukaryotic genome annotation.pdf;/home/devan/Zotero/storage/MBFL6FDV/nrg3174.html}
}

@article{zafarSiFitInferringTumor2017,
  title = {{{SiFit}}: Inferring Tumor Trees from Single-Cell Sequencing Data under Finite-Sites Models},
  shorttitle = {{{SiFit}}},
  author = {Zafar, Hamim and Tzen, Anthony and Navin, Nicholas and Chen, Ken and Nakhleh, Luay},
  year = {2017},
  month = sep,
  journal = {Genome Biology},
  volume = {18},
  number = {1},
  pages = {178},
  issn = {1474-760X},
  doi = {10.1186/s13059-017-1311-2},
  abstract = {Single-cell sequencing enables the inference of tumor phylogenies that provide insights on intra-tumor heterogeneity and evolutionary trajectories. Recently introduced methods perform this task under the infinite-sites assumption, violations of which, due to chromosomal deletions and loss of heterozygosity, necessitate the development of inference methods that utilize finite-sites models. We propose a statistical inference method for tumor phylogenies from noisy single-cell sequencing data under a finite-sites model. The performance of our method on synthetic and experimental data sets from two colorectal cancer patients to trace evolutionary lineages in primary and metastatic tumors suggests that employing a finite-sites model leads to improved inference of tumor phylogenies.},
  keywords = {Finite-sites model,Intra-tumor heterogeneity,Phylogenetic tree,Single-cell sequencing,Tumor evolution},
  file = {/home/devan/Zotero/storage/E7WZYRPN/Zafar et al_2017_SiFit.pdf;/home/devan/Zotero/storage/YCQQWGVS/s13059-017-1311-2.html}
}

@article{zaniniPopulationGenomicsIntrapatient2015,
  title = {Population Genomics of Intrapatient {{HIV}}-1 Evolution},
  author = {Zanini, Fabio and Brodin, Johanna and Thebo, Lina and Lanz, Christa and Bratt, G{\"o}ran and Albert, Jan and Neher, Richard A},
  editor = {Chakraborty, Arup K},
  year = {2015},
  month = dec,
  journal = {eLife},
  volume = {4},
  pages = {e11282},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.11282},
  abstract = {Many microbial populations rapidly adapt to changing environments with multiple variants competing for survival. To quantify such complex evolutionary dynamics in vivo, time resolved and genome wide data including rare variants are essential. We performed whole-genome deep sequencing of HIV-1 populations in 9 untreated patients, with 6-12 longitudinal samples per patient spanning 5-8 years of infection. The data can be accessed and explored via an interactive web application. We show that patterns of minor diversity are reproducible between patients and mirror global HIV-1 diversity, suggesting a universal landscape of fitness costs that control diversity. Reversions towards the ancestral HIV-1 sequence are observed throughout infection and account for almost one third of all sequence changes. Reversion rates depend strongly on conservation. Frequent recombination limits linkage disequilibrium to about 100bp in most of the genome, but strong hitch-hiking due to short range linkage limits diversity.},
  file = {/home/devan/Zotero/storage/EP7P3CZG/Zanini et al. - 2015 - Population genomics of intrapatient HIV-1 evolutio.pdf}
}



@article{choudharySevereAcuteRespiratory2021,
  title = {Severe {{Acute Respiratory Syndrome Coronavirus}} 2 ({{SARS}}-{{CoV}}-2) {{Sequence Characteristics}} of {{Coronavirus Disease}} 2019 ({{COVID}}-19) {{Persistence}} and {{Reinfection}}},
  author = {Choudhary, Manish C and Crain, Charles R and Qiu, Xueting and Hanage, William and Li, Jonathan Z},
  year = {2021},
  month = jun,
  journal = {Clinical Infectious Diseases},
  number = {ciab380},
  issn = {1058-4838},
  doi = {10.1093/cid/ciab380},
  abstract = {Both severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) reinfection and persistent infection have been reported, but sequence characteristics in these scenarios have not been described. We assessed published cases of SARS-CoV-2 reinfection and persistence, characterizing the hallmarks of reinfecting sequences and the rate of viral evolution in persistent infection.A systematic review of PubMed was conducted to identify cases of SARS-CoV-2 reinfection and persistence with available sequences. Nucleotide and amino acid changes in the reinfecting sequence were compared with both the initial and contemporaneous community variants. Time-measured phylogenetic reconstruction was performed to compare intrahost viral evolution in persistent SARS-CoV-2 to community-driven evolution.Twenty reinfection and 9 persistent infection cases were identified. Reports of reinfection cases spanned a broad distribution of ages, baseline health status, reinfection severity, and occurred as early as 1.5 months or \&gt;8 months after the initial infection. The reinfecting viral sequences had a median of 17.5 nucleotide changes with enrichment in the ORF8 and N genes. The number of changes did not differ by the severity of reinfection and reinfecting variants were similar to the contemporaneous sequences circulating in the community. Patients with persistent coronavirus disease 2019 (COVID-19) demonstrated more rapid accumulation of sequence changes than seen with community-driven evolution with continued evolution during convalescent plasma or monoclonal antibody treatment.Reinfecting SARS-CoV-2 viral genomes largely mirror contemporaneous circulating sequences in that geographic region, while persistent COVID-19 has been largely described in immunosuppressed individuals and is associated with accelerated viral evolution.},
  file = {/home/devan/Zotero/storage/PNF7QEAE/Choudhary et al_2021_Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) Sequence.pdf;/home/devan/Zotero/storage/VW2KVFE2/6255966.html}
}

@article{ducheneTemporalSignalPhylodynamic2020,
  title = {Temporal Signal and the Phylodynamic Threshold of {{SARS}}-{{CoV}}-2},
  author = {Duchene, Sebastian and Featherstone, Leo and {Haritopoulou-Sinanidou}, Melina and Rambaut, Andrew and Lemey, Philippe and Baele, Guy},
  year = {2020},
  month = jul,
  journal = {Virus Evolution},
  volume = {6},
  number = {2},
  issn = {2057-1577},
  doi = {10.1093/ve/veaa061},
  abstract = {The ongoing SARS-CoV-2 outbreak marks the first time that large amounts of genome sequence data have been generated and made publicly available in near real time. Early analyses of these data revealed low sequence variation, a finding that is consistent with a recently emerging outbreak, but which raises the question of whether such data are sufficiently informative for phylogenetic inferences of evolutionary rates and time scales. The phylodynamic threshold is a key concept that refers to the point in time at which sufficient molecular evolutionary change has accumulated in available genome samples to obtain robust phylodynamic estimates. For example, before the phylodynamic threshold is reached, genomic variation is so low that even large amounts of genome sequences may be insufficient to estimate the virus's evolutionary rate and the time scale of an outbreak. We collected genome sequences of SARS-CoV-2 from public databases at eight different points in time and conducted a range of tests of temporal signal to determine if and when the phylodynamic threshold was reached, and the range of inferences that could be reliably drawn from these data. Our results indicate that by 2 February 2020, estimates of evolutionary rates and time scales had become possible. Analyses of subsequent data sets, that included between 47 and 122 genomes, converged at an evolutionary rate of about 1.1\,\texttimes\,10-3 subs/site/year and a time of origin of around late November 2019. Our study provides guidelines to assess the phylodynamic threshold and demonstrates that establishing this threshold constitutes a fundamental step for understanding the power and limitations of early data in outbreak genome surveillance.},
  file = {/home/devan/Zotero/storage/4JK2BDYU/Duchene et al_2020_Temporal signal and the phylodynamic threshold of SARS-CoV-2.pdf;/home/devan/Zotero/storage/NFAFGLVC/5894560.html}
}

@article{geidelbergGenomicEpidemiologyDensely2021,
  title = {Genomic Epidemiology of a Densely Sampled {{COVID}}-19 Outbreak in {{China}}},
  author = {Geidelberg, Lily and Boyd, Olivia and Jorgensen, David and Siveroni, Igor and Nascimento, Fabr{\'i}cia F and Johnson, Robert and {Ragonnet-Cronin}, Manon and Fu, Han and Wang, Haowei and Xi, Xiaoyue and Chen, Wei and Liu, Dehui and Chen, Yingying and Tian, Mengmeng and Tan, Wei and Zai, Junjie and Sun, Wanying and Li, Jiandong and Li, Junhua and Volz, Erik M and Li, Xingguang and Nie, Qing},
  year = {2021},
  month = jan,
  journal = {Virus Evolution},
  volume = {7},
  number = {1},
  issn = {2057-1577},
  doi = {10.1093/ve/veaa102},
  abstract = {Analysis of genetic sequence data from the SARS-CoV-2 pandemic can provide insights into epidemic origins, worldwide dispersal, and epidemiological history. With few exceptions, genomic epidemiological analysis has focused on geographically distributed data sets with few isolates in any given location. Here, we report an analysis of 20 whole SARS- CoV-2 genomes from a single relatively small and geographically constrained outbreak in Weifang, People's Republic of China. Using Bayesian model-based phylodynamic methods, we estimate a mean basic reproduction number (R0) of 3.4 (95\% highest posterior density interval: 2.1\textendash 5.2) in Weifang, and a mean effective reproduction number (Rt) that falls below 1 on 4 February. We further estimate the number of infections through time and compare these estimates to confirmed diagnoses by the Weifang Centers for Disease Control. We find that these estimates are consistent with reported cases and there is unlikely to be a large undiagnosed burden of infection over the period we studied.},
  file = {/home/devan/Zotero/storage/KFA433Q2/Geidelberg et al_2021_Genomic epidemiology of a densely sampled COVID-19 outbreak in China.pdf;/home/devan/Zotero/storage/IVV5LR7K/6170691.html}
}

@article{niePhylogeneticPhylodynamicAnalyses2020,
  title = {Phylogenetic and Phylodynamic Analyses of {{SARS}}-{{CoV}}-2},
  author = {Nie, Qing and Li, Xingguang and Chen, Wei and Liu, Dehui and Chen, Yingying and Li, Haitao and Li, Dongying and Tian, Mengmeng and Tan, Wei and Zai, Junjie},
  year = {2020},
  month = oct,
  journal = {Virus Research},
  volume = {287},
  pages = {198098},
  issn = {0168-1702},
  doi = {10.1016/j.virusres.2020.198098},
  abstract = {To investigate the evolutionary and epidemiological dynamics of the current COVID-19 outbreak, a total of 112 genomes of SARS-CoV-2 strains sampled from China and 12 other countries with sampling dates between 24 December 2019 and 9 February 2020 were analyzed. We performed phylogenetic, split network, likelihood-mapping, model comparison, and phylodynamic analyses of the genomes. Based on Bayesian time-scaled phylogenetic analysis with the best-fitting combination models, we estimated the time to the most recent common ancestor (TMRCA) and evolutionary rate of SARS-CoV-2 to be 12 November 2019 (95 \% BCI: 11 October 2019 and 09 December 2019) and 9.90 \texttimes{} 10-4 substitutions per site per year (95 \% BCI: 6.29 \texttimes{} 10-4\textendash 1.35 \texttimes{} 10-3), respectively. Notably, the very low Re estimates of SARS-CoV-2 during the recent sampling period may be the result of the successful control of the pandemic in China due to extreme societal lockdown efforts. Our results emphasize the importance of using phylodynamic analyses to provide insights into the roles of various interventions to limit the spread of SARS-CoV-2 in China and beyond.},
  language = {en},
  keywords = {COVID-19,Evolutionary rate,Lockdown,SARS-CoV-2,TMRCA},
  file = {/home/devan/Zotero/storage/6AZFTGR9/Nie et al_2020_Phylogenetic and phylodynamic analyses of SARS-CoV-2.pdf;/home/devan/Zotero/storage/IZENKGEX/S0168170220307152.html}
}

@article{songGenomicEpidemiologySARSCoV22021,
  title = {Genomic {{Epidemiology}} of {{SARS}}-{{CoV}}-2 {{From Mainland China With Newly Obtained Genomes From Henan Province}}},
  author = {Song, Ning and Cui, Guang-Lin and Zeng, Qing-Lei},
  year = {2021},
  month = may,
  journal = {Frontiers in Microbiology},
  volume = {12},
  pages = {673855},
  issn = {1664-302X},
  doi = {10.3389/fmicb.2021.673855},
  abstract = {Even though the COVID-19 epidemic in China has been successfully put under control within a few months, it is still very important to infer the origin time and genetic diversity from the perspective of the whole genome sequence of its agent, SARS-CoV-2. Yet, the sequence of the entire virus genome from China in the current public database is very unevenly distributed with reference to time and place of collection. In particular, only one sequence was obtained in Henan province, adjacent to China's worst-case province, Hubei Province. Herein, we used high-throughput sequencing techniques to get 19 whole-genome sequences of SARS-CoV-2 from 18 severe patients admitted to the First Affiliated Hospital of Zhengzhou University, a provincial designated hospital for the treatment of severe COVID-19 cases in Henan province. The demographic, baseline, and clinical characteristics of these patients were described. To investigate the molecular epidemiology of SARS-CoV-2 of the current COVID-19 outbreak in China, 729 genome sequences (including 19 sequences from this study) sampled from Mainland China were analyzed with state-of-the-art comprehensive methods, including likelihood-mapping, split network, ML phylogenetic, and Bayesian time-scaled phylogenetic analyses. We estimated that the evolutionary rate and the time to the most recent common ancestor (TMRCA) of SARS-CoV-2 from Mainland China were 9.25 \texttimes{} 10               -4               substitutions per site per year (95\% BCI: 6.75 \texttimes{} 10               -4               to 1.28 \texttimes{} 10               -3               ) and October 1, 2019 (95\% BCI: August 22, 2019 to November 6, 2019), respectively. Our results contribute to studying the molecular epidemiology and genetic diversity of SARS-CoV-2 over time in Mainland China.},
  language = {en},
  file = {/home/devan/Zotero/storage/UJ5KA47S/Song et al. - 2021 - Genomic Epidemiology of SARS-CoV-2 From Mainland C.pdf}
}



@misc{IssuesSARSCoV2Sequencing2020,
  title = {Issues with {{SARS}}-{{CoV}}-2 Sequencing Data - {{SARS}}-{{CoV}}-2 Coronavirus / {{nCoV}}-2019 {{Genomic Epidemiology}}},
  year = {2020},
  month = may,
  journal = {Virological},
  abstract = {Issues with SARS-CoV-2 sequencing data Nicola De Maio1*, Conor Walker1, Rui Borges2, Lukas Weilguny1, Greg Slodkowicz3, Nick Goldman1  1European Molecular Biology Laboratory, European Bioinformatics Institute, Hinxton, Cambridgeshire, United Kingdom.  2Institut f\"ur Populationsgenetik, Vetmeduni Vienna, Veterin\"arplatz 1, Wien 1210, Austria.  3MRC Laboratory of Molecular Biology, Francis Crick Avenue, Cambridge Biomedical Campus, Cambridge CB2 0QH, United Kingdom.  *demaio@ebi.ac.uk  Summary We in...},
  howpublished = {https://virological.org/t/issues-with-sars-cov-2-sequencing-data/473},
  langid = {english},
  file = {/home/devan/Zotero/storage/KRG4ETZ3/473.html}
}


